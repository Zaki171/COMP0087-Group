{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICL - GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Device being used: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk, load_metric\n",
    "import bert_score\n",
    "import evaluate\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device being used:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "sent_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def sent_similarity(sent1, sent2):\n",
    "    sentences = [sent1, sent2]\n",
    "    embeddings = sent_model.encode(sentences)\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    return similarity_matrix[0][1]\n",
    "\n",
    "# def sent_similarity(prompt, sentences):\n",
    "#     P, R, F1 = bert_score.score([prompt]*len(sentences),sentences, lang=\"en\")\n",
    "#     return F1.tolist()\n",
    "\n",
    "\n",
    "def format_examples(ds, ds_name='ni'):\n",
    "    prompts = []\n",
    "    if ds_name == 'ni':\n",
    "        for example in ds:\n",
    "            # prompt = f\"### Question: {example['input']} \\n ###Targets: {example['output']}\"\n",
    "            prompt = f\"### Task: {example['definition']}\\n ### Inputs: {example['inputs']}\\n ### Targets: {example['targets']}\"\n",
    "            prompts.append(prompt)\n",
    "    elif ds_name == 'medmcq':\n",
    "         for example in ds:\n",
    "            prompt = f\"### Task: {example['instruction']}\\n ### Question: {example['input']}\\n ### Answer: {example['output']}\"\n",
    "            prompts.append(prompt)\n",
    "    elif ds_name == 'finance_sent':\n",
    "        for example in ds:\n",
    "            prompt = f\"### Text: {example['text']}\\n ### Targets: {example['label']}\"\n",
    "            prompts.append(prompt)\n",
    "    elif ds_name == 'medqa':\n",
    "        for example in ds:\n",
    "            prompts.append(example['text'])\n",
    "    elif ds_name == 'lawqa':\n",
    "        for example in ds:\n",
    "            prompt = f\"### Question: {example['question']}\\n ### Answer: {example['answer']}\"\n",
    "            prompts.append(prompt)\n",
    "    elif ds_name == 'alpaca':\n",
    "        for example in ds:\n",
    "            prompt = f\"### Instruction: {example['instruction']}\\n ### Input: {example['input']}\\n ### Text: {example['text']} \\n ### Output: {example['output']}\"\n",
    "            prompts.append(prompt)\n",
    "\n",
    "    return prompts\n",
    "\n",
    "def select_characters_before_target(string, target_phrase=\"\\n ### Targets:\"): #this is a function to remove the actual target values from the train example so that the matching can be improved\n",
    "    target_index = string.find(target_phrase)\n",
    "    if target_index != -1:  # If the phrase is found\n",
    "        return string[:target_index] + target_phrase\n",
    "    else:\n",
    "        return string \n",
    "    \n",
    "def extract_response_content(string, target_phrase):\n",
    "    response_index = string.find(target_phrase)\n",
    "    return string[response_index + len(target_phrase):].strip()\n",
    "\n",
    "def group_examples_random(ds, n): #this is where we group examples into a larger prompt\n",
    "    random.seed()\n",
    "    samples = random.sample(ds, n)\n",
    "    new_prompt = \"\"\n",
    "    for i in range(n):\n",
    "        new_prompt += samples[i]\n",
    "        new_prompt += \"\\n\"\n",
    "    return new_prompt\n",
    "\n",
    "def create_similarity_dict(prompt, train_ds, n_egs=5, target_phrase=\"\\n ### Targets:\"):\n",
    "    similarity_dict = {}\n",
    "    for eg in train_ds:\n",
    "        similarity_dict[eg] = sent_similarity(prompt, select_characters_before_target(eg, target_phrase))\n",
    "    sorted_dict = sorted(similarity_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_egs = []\n",
    "    for item in sorted_dict[:n_egs]:\n",
    "        top_egs.append(item[0])\n",
    "    return top_egs\n",
    "\n",
    "\n",
    "def group_by_similarity(prompt, ds, n_egs, m_choices, target_phrase=\"\\n ### Targets:\"):\n",
    "    random.seed(42)\n",
    "    choices = random.sample(ds, m_choices)\n",
    "    cos_sim_dict = {}\n",
    "    # bert_scores = sent_similarity(prompt, choices)\n",
    "    # choices_with_scores = list(zip(choices, bert_scores))\n",
    "\n",
    "    # sorted_choices = sorted(choices_with_scores, key=lambda x: x[1], reverse=True)\n",
    "    # top_egs = \"\"\n",
    "    # for choice, _ in sorted_choices[:n_egs]:\n",
    "    #     top_egs += choice\n",
    "    #     top_egs += \"\\n\"\n",
    "\n",
    "    # return top_egs\n",
    "    \n",
    "\n",
    "    for c in choices:\n",
    "        cos_sim_dict[c] = sent_similarity(prompt, select_characters_before_target(c, target_phrase))\n",
    "\n",
    "    sorted_cos_sim = sorted(cos_sim_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_egs = \"\"\n",
    "    for item in sorted_cos_sim[:n_egs]:\n",
    "        top_egs += item[0]\n",
    "        top_egs += \"\\n\"\n",
    "\n",
    "    # top_egs = \"\".join([item[0] for item in sorted_cos_sim[:n_egs]])\n",
    "    return top_egs\n",
    "\n",
    "def count_tokens(tokenizer, prompt):\n",
    "    input_ids = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "    return len(input_ids)\n",
    "\n",
    "\n",
    "def evaluate_example(model, tokenizer, prompt, model_name, max_tokens):\n",
    "    if model_name == 'gpt2_small':\n",
    "        num_tokens = count_tokens(tokenizer, prompt)\n",
    "        if num_tokens >= 900:\n",
    "            return None\n",
    "        print(max_tokens, num_tokens)\n",
    "        model_inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        outputs =model.generate(**model_inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=max_tokens) #set max_length to 1024 since GPT2 doesnt take nearly as long with ICL\n",
    "        decoded_output = tokenizer.decode(outputs[0][len(model_inputs['input_ids'][0]):], skip_special_tokens=True)\n",
    "        return decoded_output\n",
    "    elif model_name == 'mistral':\n",
    "        # num_tokens = count_tokens(tokenizer, prompt)\n",
    "        # print(\"Num tokens in prompt: \", num_tokens)\n",
    "        # if num_tokens > 3400:\n",
    "        #     return None\n",
    "        model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        print(\"Max number of tokens: \", max_tokens)\n",
    "        outputs =model.generate(**model_inputs, pad_token_id=tokenizer.eos_token_id, do_sample=True, max_new_tokens=max_tokens)\n",
    "        decoded_output = tokenizer.decode(outputs[0][len(model_inputs['input_ids'][0]):], skip_special_tokens=True) #only get output\n",
    "        return decoded_output\n",
    "  \n",
    "\n",
    "def evaluate_icl(train_dataset, test_dataset, model, tokenizer, num_egs, model_name, ds_name='ni', method='similarity', max_tokens_dict=None):\n",
    "    reals = []\n",
    "    preds = []\n",
    "    counter = 0\n",
    "    for example in test_dataset:\n",
    "        # prompt = group_examples(train_dataset, num_egs) + f\"### Question: {example['input']} \\n ###Targets:\"\n",
    "        target_phrase = \"\\n ### Targets:\"\n",
    "        if ds_name == 'ni':\n",
    "            curr_prompt = f\"### Task: {example['definition']}\\n ### Inputs: {example['inputs']}\\n ### Targets:\"\n",
    "            real = f\"{example['targets']}\"\n",
    "            max_tokens = max_tokens_dict[real] + 100\n",
    "        elif ds_name == 'medmcq':\n",
    "            curr_prompt = f\"### Task: {example['instruction']}\\n ### Question: {example['input']}\\n ### Answer:\"\n",
    "            real = f\"{example['output']}\"\n",
    "            tokens = tokenizer(real, return_tensors='pt').to(device)\n",
    "            max_tokens = len(tokens['input_ids'][0]) + 10\n",
    "            target_phrase=\"### Answer:\"\n",
    "        elif ds_name == 'finance_sent':\n",
    "            curr_prompt = f\"### Text: {example['text']}\\n ### Targets:\"\n",
    "            real = f\"{example['label']}\"\n",
    "            tokens = tokenizer(real, return_tensors='pt').to(device)\n",
    "            max_tokens = len(tokens['input_ids'][0]) + 10\n",
    "        elif ds_name == 'medqa':\n",
    "            curr_prompt = select_characters_before_target(example['text'], \"### Response:\")\n",
    "            real = extract_response_content(example['text'], \"### Response:\")\n",
    "            max_tokens = max_tokens_dict[real] + 100\n",
    "        elif ds_name == 'lawqa':\n",
    "            curr_prompt = f\"### Question: {example['question']}\\n ### Answer:\"\n",
    "            real = example['answer']\n",
    "            max_tokens = max_tokens_dict[real] + 100\n",
    "            target_phrase = \"### Answer:\"\n",
    "        elif ds_name == 'alpaca':\n",
    "            curr_prompt = f\"### Instruction: {example['instruction']}\\n ### Input: {example['input']}\\n ### Text: {example['text']}\\n ### Output:\"\n",
    "            real = example['output']\n",
    "            max_tokens = max_tokens_dict[real]+100\n",
    "            target_phrase=\"### Output:\"\n",
    "\n",
    "        # tokens = tokenizer(real, return_tensors='pt').to(device)\n",
    "        # max_tokens = len(tokens['input_ids'][0])\n",
    "    \n",
    "        if method == 'similarity':\n",
    "            icl_prompt = group_by_similarity(curr_prompt, train_dataset, num_egs, 250, target_phrase) + curr_prompt\n",
    "        elif method == 'random':\n",
    "            icl_prompt = group_examples_random(train_dataset, num_egs) + curr_prompt\n",
    "\n",
    "        # print(\"MAX TOKENS:\\n\", max_tokens)\n",
    "        # print(\"\\n ICL Prompt: \",icl_prompt)\n",
    "        print(\"ICL prompt complete\")\n",
    "        pred = evaluate_example(model, tokenizer, icl_prompt, model_name, max_tokens)\n",
    "        print(\"Prediction complete\")\n",
    "\n",
    "        if counter % 50 == 0:\n",
    "            print(\"PROMPT:\\n\", icl_prompt)\n",
    "            print(\"REAL ANSWER:\\n\", real)\n",
    "            print(\"PREDICTION:\\n\", pred)\n",
    "        if pred:\n",
    "            reals.append(real.lower())\n",
    "            preds.append(pred.lower())\n",
    "        counter+=1\n",
    "\n",
    "    return reals, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n\u001b[0;32m      2\u001b[0m tokenizer_mist_8\u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model_mist_8 \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistralai/Mistral-7B-v0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    567\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3502\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3494\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3495\u001b[0m     (\n\u001b[0;32m   3496\u001b[0m         model,\n\u001b[0;32m   3497\u001b[0m         missing_keys,\n\u001b[0;32m   3498\u001b[0m         unexpected_keys,\n\u001b[0;32m   3499\u001b[0m         mismatched_keys,\n\u001b[0;32m   3500\u001b[0m         offload_index,\n\u001b[0;32m   3501\u001b[0m         error_msgs,\n\u001b[1;32m-> 3502\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3510\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3520\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[0;32m   3521\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3926\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   3924\u001b[0m                     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, state_dict)\n\u001b[0;32m   3925\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3926\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3930\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3933\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3934\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3935\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3936\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3937\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3938\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3939\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3940\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3941\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3942\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3943\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[0;32m   3944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:807\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[1;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[0;32m    805\u001b[0m         set_module_tensor_to_device(model, param_name, param_device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mset_module_kwargs)\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 807\u001b[0m         \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_quantized_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;66;03m# TODO: consider removing used param_parts from state_dict before return\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, offload_index, state_dict_index\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_8bit.py:200\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.create_quantized_param\u001b[1;34m(self, model, param_value, param_name, target_device, state_dict, unexpected_keys)\u001b[0m\n\u001b[0;32m    197\u001b[0m         new_value \u001b[38;5;241m=\u001b[39m new_value\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    199\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m old_value\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m--> 200\u001b[0m new_value \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInt8Params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m new_value\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fp16_statistics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:538\u001b[0m, in \u001b[0;36mInt8Params.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    529\u001b[0m device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    531\u001b[0m )\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    534\u001b[0m     device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    537\u001b[0m ):\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    540\u001b[0m     new_param \u001b[38;5;241m=\u001b[39m Int8Params(\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m    542\u001b[0m             device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         has_fp16_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_fp16_weights,\n\u001b[0;32m    546\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:501\u001b[0m, in \u001b[0;36mInt8Params.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcuda(device)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# we store the 8-bit rows-major weight\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# we convert this weight to the turning/ampere weight during the first inference pass\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m     CB, CBt, SCB, SCBt, coo_tensorB \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdouble_quant(B)\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m CBt\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "tokenizer_mist_8= AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "model_mist_8 = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\",  load_in_8bit=True, device_map='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:37<00:00, 18.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model_plain =  GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "# tokenizer_plain = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# print(\"models retrieved\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "load_in_4bit=True,\n",
    "bnb_4bit_use_double_quant=True,\n",
    "bnb_4bit_quant_type=\"nf4\",\n",
    "bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model_mist = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", quantization_config=bnb_config, device_map=\"auto\")\n",
    "tokenizer_mist = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "model_gpt2=  GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_example2(model, tokenizer, prompt):\n",
    "    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "    # print(prompt)\n",
    "    # if len(tokenized_prompt['input_ids'][0]) > MAX_LENGTH: #currently just checking if random prompt is too big or not\n",
    "    #     return None \n",
    "    outputs =model.generate(**model_inputs, pad_token_id= tokenizer.eos_token_id, do_sample=False, max_new_tokens = 5)\n",
    "    decoded_output = tokenizer.decode(outputs[0][len(model_inputs['input_ids'][0]):], skip_special_tokens=True)\n",
    "    # print(\"prediction: \",decoded_output)/\n",
    "    return decoded_output\n",
    "\n",
    "\n",
    "prompt = \"\"\" \"featuring an oscar-worthy performance => positive\\n\"\n",
    "    \"completely messed up => negative\\n\"\n",
    "    \"masterpiece => positive\\n\"\n",
    "    \"the action is stilted => negative\\n\"\n",
    "    \"by far the worst movie of the year =>\" \"\"\"\n",
    "pred = evaluate_example2(model_mist_8, tokenizer_mist_8, prompt) \n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\zakit\\.cache\\huggingface\\metrics\\bleurt\\bleurt-large-512\\downloads\\extracted\\3f937bb8d45f43db16ed64e68427a81be6250c9c6b0704e2e5ce3e3099d274c8\\bleurt-large-512.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\zakit\\.cache\\huggingface\\metrics\\bleurt\\bleurt-large-512\\downloads\\extracted\\3f937bb8d45f43db16ed64e68427a81be6250c9c6b0704e2e5ce3e3099d274c8\\bleurt-large-512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bleurt = evaluate.load(\"bleurt\",'bleurt-large-512')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Natural Instructions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zakit\\AppData\\Local\\Temp\\ipykernel_35032\\3286132499.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_test_dataset = test_dataset.to_pandas().groupby('task_name').apply(lambda x: x.head(10)).reset_index(drop=True) #pick an array of tasks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set:  100\n",
      "Length of train set 487107\n",
      "ICL prompt complete\n",
      "102 112\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: The answer will be 'yes' if the provided sentence contains an explicit mention that answers the given question. Otherwise, the answer should be 'no'. Instances where the answer is implied from the sentence using \"instinct\" or \"common sense\" (as opposed to being written explicitly in the sentence) should be labeled as 'no'.\n",
      " ### Inputs: Sentence: Jerry goes out to the pier and casts his favorite bait : cheese . \n",
      "Question: How much time did Jerry spend at the pier?\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " No.\n",
      "PREDICTION:\n",
      "  Jerry, Jerry's wife, Jerry's girlfriend, Jerry's best friend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best friend's girlfriend, Jerry's best\n",
      "ICL prompt complete\n",
      "102 126\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 106\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 113\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 117\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 117\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 109\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 110\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "103 103\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 800\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "133 813\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 800\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 797\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "124 804\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "122 802\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 798\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 798\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "122 802\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "116 796\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "119 374\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "121 376\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 375\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 375\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 375\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 373\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "119 374\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 377\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "122 378\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 375\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "104 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "106 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "104 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "104 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 93\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "107 93\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 119\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Generate an overlapping word between the given two sentences. When you find the overlapping words, they don't have to match exactly, e.g., \"survival\" and \"survive\" are valid overlapping words. Little words like \"the\" or \"of\" don't count! You must generate significant words which are not the stop words.\n",
      " ### Inputs: Sentence1: Some parasites kill their host, but most do not. \n",
      "Sentence2: All parasites are harmful to their host, but some are beneficial to humans.\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " host\n",
      "PREDICTION:\n",
      "  The target of the sentence is the parasite.\n",
      "### Output: The output of the sentence is the word that is the target of the sentence.\n",
      "### Output: The output of the sentence is the word that is the target of the sentence.\n",
      "### Output: The output of the sentence is the word that is the target of the sentence.\n",
      "### Output: The output of the sentence is the word that is the target of the sentence.\n",
      "### Output: The output of the sentence is the word\n",
      "ICL prompt complete\n",
      "101 122\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 132\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 132\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 132\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 132\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 132\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 132\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 110\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 131\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 113\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 110\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 118\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 110\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 148\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "108 99\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "110 99\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "109 99\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "107 99\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "108 99\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "110 99\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "106 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 98\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "106 99\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 101\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 101\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 125\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 124\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ICL prompt complete\n",
      "102 217\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: You are given a sentence, a question and two answer options ('A' and 'B'). Your task is to find the correct answer (return the string of the correct option, not 'A' or 'B') for the given question.\n",
      " ### Inputs: Sentence: Stabbing a fork into a steak causes it to move slower then stabbing it into a muffin. Question: Which surface provides less resistance? (A) muffin (B) steak\n",
      " ### Targets: muffin\n",
      "### Task: The answer will be 'yes' if the provided sentence contains an explicit mention that answers the given question. Otherwise, the answer should be 'no'. Instances where the answer is implied from the sentence using \"instinct\" or \"common sense\" (as opposed to being written explicitly in the sentence) should be labeled as 'no'.\n",
      " ### Inputs: Sentence: Jerry goes out to the pier and casts his favorite bait : cheese . \n",
      "Question: How much time did Jerry spend at the pier?\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " No.\n",
      "PREDICTION:\n",
      "  cheese\n",
      "### Task: The answer will be 'yes' if the provided sentence contains an explicit mention that answers the given question. Otherwise, the answer should be 'no'. Instances where the answer is implied from the sentence using \"instinct\" or \"common sense\" (as opposed to being written explicitly in the sentence) should be labeled as 'no'.\n",
      " ### Inputs: Sentence: Jerry goes out to the pier and casts his favorite bait : cheese. \n",
      "Question: How much time\n",
      "ICL prompt complete\n",
      "102 214\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 233\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 190\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 200\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 261\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 268\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 171\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 186\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 232\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 171\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 175\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 197\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 199\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 201\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 202\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "103 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 197\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 203\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 197\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 888\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 888\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 885\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "124 892\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "122 890\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 886\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 886\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "122 890\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "116 884\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "119 428\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "121 430\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 429\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 429\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 429\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 427\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "119 428\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 431\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "122 432\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 429\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "104 193\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 193\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "106 193\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "104 193\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 193\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 193\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 193\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "104 193\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 212\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "107 212\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 188\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Given a set of five words, generate the word from the set that does not belong (i.e. is the least relevant) with the other words. Words are separated by commas.\n",
      " ### Inputs: fritter, croquet, dessert, seperate, doughnut\n",
      " ### Targets: seperate\n",
      "### Task: Generate an overlapping word between the given two sentences. When you find the overlapping words, they don't have to match exactly, e.g., \"survival\" and \"survive\" are valid overlapping words. Little words like \"the\" or \"of\" don't count! You must generate significant words which are not the stop words.\n",
      " ### Inputs: Sentence1: Some parasites kill their host, but most do not. \n",
      "Sentence2: All parasites are harmful to their host, but some are beneficial to humans.\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " host\n",
      "PREDICTION:\n",
      "  ~~~\n",
      "### Task: Generate a word from the set that does not belong (i.e. is the least relevant) with the other words. Words are separated by commas.\n",
      "### Inputs: fritter, croquet, dessert, seperate, doughnut\n",
      "### Targets: ~~~\n",
      "### Task: Generate an overlapping word between the given two sentences. When you find the overlapping words, they don't have to match exactly, e.g.,\n",
      "ICL prompt complete\n",
      "101 191\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 201\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 201\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 201\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 201\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 201\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 201\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 179\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 200\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 223\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 232\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 197\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 191\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 226\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 195\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 200\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 232\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "108 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "110 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "109 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "107 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "108 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "110 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 168\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "106 168\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 168\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "106 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 250\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 208\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 148\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 195\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 205\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 261\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 171\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 229\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 303\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 298\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 171\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 261\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 338\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 303\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ICL prompt complete\n",
      "102 317\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: You are given a sentence, a question and two answer options ('A' and 'B'). Your task is to find the correct answer (return the string of the correct option, not 'A' or 'B') for the given question.\n",
      " ### Inputs: Sentence: Stabbing a fork into a steak causes it to move slower then stabbing it into a muffin. Question: Which surface provides less resistance? (A) muffin (B) steak\n",
      " ### Targets: muffin\n",
      "### Task: In this task, You are given an open-domain question that can be answered based on factual information. Your task is to provide \\*short\\* answer (in a few words only) for the given question. The short answer can be one or more entities or it can also be boolean \\*yes\\* or \\*no\\*.\n",
      " ### Inputs: who played scarlet o'hara in gone with the wind\n",
      " ### Targets: Vivien Leigh\n",
      "### Task: The answer will be 'yes' if the provided sentence contains an explicit mention that answers the given question. Otherwise, the answer should be 'no'. Instances where the answer is implied from the sentence using \"instinct\" or \"common sense\" (as opposed to being written explicitly in the sentence) should be labeled as 'no'.\n",
      " ### Inputs: Sentence: Jerry goes out to the pier and casts his favorite bait : cheese . \n",
      "Question: How much time did Jerry spend at the pier?\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " No.\n",
      "PREDICTION:\n",
      "  Jerry\n",
      "### Task: The answer will be 'yes' if the provided sentence contains an explicit mention that answers the given question. Otherwise, the answer should be 'no'. Instances where the answer is implied from the sentence using \"instinct\" or \"common sense\" (as opposed to being written explicitly in the sentence) should be labeled as 'no'.\n",
      " ### Inputs: Sentence: Jerry goes out to the pier and casts his favorite bait : cheese. \n",
      "Question: How much time\n",
      "ICL prompt complete\n",
      "102 305\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 320\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 327\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 378\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 385\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 288\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 303\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 352\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 315\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 267\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 263\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 269\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 271\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 268\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "103 239\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 267\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 259\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 267\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "119 548\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "121 550\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 549\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 549\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 549\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 547\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "119 548\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 551\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "122 552\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 549\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "104 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "106 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "104 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "104 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "107 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 251\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Given a set of five words, generate the word from the set that does not belong (i.e. is the least relevant) with the other words. Words are separated by commas.\n",
      " ### Inputs: fritter, croquet, dessert, seperate, doughnut\n",
      " ### Targets: seperate\n",
      "### Task: Given a set of five words, generate the word from the set that does not belong (i.e. is the least relevant) with the other words. Words are separated by commas.\n",
      " ### Inputs: fine, alright, light, just, fair\n",
      " ### Targets: light\n",
      "### Task: Generate an overlapping word between the given two sentences. When you find the overlapping words, they don't have to match exactly, e.g., \"survival\" and \"survive\" are valid overlapping words. Little words like \"the\" or \"of\" don't count! You must generate significant words which are not the stop words.\n",
      " ### Inputs: Sentence1: Some parasites kill their host, but most do not. \n",
      "Sentence2: All parasites are harmful to their host, but some are beneficial to humans.\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " host\n",
      "PREDICTION:\n",
      "  parasite\n",
      "### Task: Generate an overlapping word between the given two sentences. When you find the overlapping words, they don't have to match exactly, e.g., \"survival\" and \"survive\" are valid overlapping words. Little words like \"the\" or \"of\" don't count! You must generate significant words which are not the stop words.\n",
      " ### Inputs: Sentence1: Some parasites kill their host, but most do not. \n",
      "Sentence2:\n",
      "ICL prompt complete\n",
      "101 254\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 264\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 264\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 264\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 264\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 264\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 264\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 324\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 289\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 316\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 297\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 311\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 294\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 326\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 315\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 300\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 308\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 327\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "108 235\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "110 235\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "109 235\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "107 228\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "108 228\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "110 228\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 227\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "106 227\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "105 227\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "106 238\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 289\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 387\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 302\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 260\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 286\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 286\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 337\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 285\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 299\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 474\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 237\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 285\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 477\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 487\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "102 305\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 276\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 366\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 443\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "101 511\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = tokenizer_gpt2\n",
    "model = model_gpt2\n",
    "\n",
    "data = load_from_disk('data/1000_per_task')\n",
    "\n",
    "# data = filter_icl(data, max_num_egs, tokenizer_plain)\n",
    "\n",
    "max_num_egs =  3   #natural instructions are just too big\n",
    "\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "# train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "# train_dataset = train_test_split['train']\n",
    "# test_dataset = train_test_split['test']\n",
    "\n",
    "train_dataset = data['train']\n",
    "test_dataset = data['test']\n",
    "\n",
    "grouped_test_dataset = test_dataset.to_pandas().groupby('task_name').apply(lambda x: x.head(10)).reset_index(drop=True) #pick an array of tasks\n",
    "\n",
    "test_dataset = Dataset.from_pandas(grouped_test_dataset.head(100))\n",
    "\n",
    "\n",
    "icl_method = 'similarity'\n",
    "model_name = 'gpt2_small'\n",
    "ds_name = 'ni'\n",
    "\n",
    "def filter_example(example):\n",
    "    return count_tokens(tokenizer, f\"### Task: {example['definition']}\\n ### Inputs: {example['inputs']}\\n ### Targets: {example['targets']}\") <= 300 #speeds up process\n",
    "\n",
    "train_dataset = train_dataset.filter(filter_example)\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name=\"ni\")\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "max_token_dict = {}\n",
    "for eg in test_dataset:\n",
    "    max_token_dict[eg['targets']] = count_tokens(tokenizer, eg['targets'])\n",
    "\n",
    "# csv_file = f'icl_results/similarity_dicts_{ds_name}.csv'\n",
    "# if os.path.isfile(csv_file):\n",
    "#     df = pd.read_csv(csv_file)\n",
    "#     test_similarity_dict = dict(zip(df['Prompt'], df['Similar_Prompts']))\n",
    "# else:\n",
    "#     test_similarity_dict = {}\n",
    "#     for eg in test_dataset:\n",
    "#         prompt = f\"### Task: {eg['definition']}\\n ### Inputs: {eg['inputs']}\\n ### Targets:\"\n",
    "#         test_similarity_dict[eg] = create_similarity_dict(prompt, train_list)\n",
    "#     print(test_similarity_dict)\n",
    "#     df = pd.DataFrame(list(test_similarity_dict.items()), columns=['Prompt', 'Similar_Prompts'])\n",
    "#     df.to_csv(csv_file, index=False)\n",
    "\n",
    "# print(test_similarity_dict)\n",
    "\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "for i in range(max_num_egs):\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model, tokenizer, i, model_name=model_name, ds_name=ds_name, method=icl_method, max_tokens_dict=max_token_dict)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    print(order)\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order= order) #set order to mean of real values\n",
    "    bleurt_score = bleurt.compute(predictions=preds, references=reals)\n",
    "    avg_bleurt = sum(bleurt_score['scores'])/len(bleurt_score['scores'])\n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations':i, 'bert_score' : float(average_F1), 'bleu_score': bleu_score['bleu'], 'bleurt_score' : avg_bleurt})\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/{icl_method}/icl_results_{ds_name}_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Alpaca Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set:  100\n",
      "Length of train set 33633\n",
      "{'The maximum number of steps in a Fibonacci sequence is 93.': 18, 'An example of the Second Law of Thermodynamics is when heat flows from a hot object to a cold object. The hot object cools down, and the cold object warms up, but the energy is not conserved and some of the heat energy is lost.': 56, \"It's time to get ready for the thrilling new movie! Get ready to experience edge-of-your-seat suspense, nail-biting suspense, and clever twists. #MovieNight #UpcomingMovie\": 52, 'Prime numbers: 5, 31\\nComposite numbers: 16, 9, 18': 25, 'Simile.': 4, 'A good exercise routine should incorporate aerobic exercise, strength training, and flexibility exercises. Examples of aerobic activities include walking, jogging, biking, or swimming. Strength training exercises include lifting weights, using resistance bands and bodyweight exercises. Flexibility exercises include stretching and yoga. A well structured routine should also have rest and recovery days.': 75, '^[A-Z][a-z]+$': 12, 'The potential issue with the argument is that it does not take into account any potential disadvantages of raising the minimum wage. There may be unintended consequences such as businesses raising prices to offset their increased labour costs, resulting in higher cost of living for the consumer. This could ultimately lead to decreased demand for goods and services, resulting in fewer jobs available for the workers in the long run.': 81, 'We had a good time!': 7, 'How about a weekend getaway to the town of Mendocino in California? Spend the first day exploring the stunning cliffs overlooking the Pacific Ocean and kayaking in the calm waters. Spend the second day exploring the charming village, visiting the top-notch wineries, and doing some light shopping and souvenir finding. End the weekend with a romantic dinner at Café Beaujolais and catching the breathtaking sunsets from the bluffs.': 100, 'Five other methods to measure air quality include:\\n- monitoring of ambient air concentrations and emissions\\n- remote sensing techniques (e.g. satellite imaging)\\n- establishing regional monitoring networks\\n- collecting and analyzing in-situ samples \\n- measurement of deposition and aerosols': 64, '|  Column 1  |  Column 2  |  Column 3  |\\n|:----------:|:----------:|:----------:|\\n|      1     |      4     |      7     |\\n|      2     |      5     |      8     |\\n|      3     |      6     |      9     |\\n|            |      10    |            |': 87, 'From self-driving cars to robot surgeons - #artificialintelligence is revolutionizing our lives! #AI #FutureTech': 29, 'Some common elements found in horror movies are suspense, dark atmosphere, jump scares, mysterious and terrifying characters, unexpected twists, and graphic violence and gore.': 36, 'A system should be created for amplifying user feedback to ensure that users’ ideas and suggestions are heard and taken into account. The system should involve collecting user feedback from various sources, including surveys, social media, and customer reviews. The collected feedback should then be sorted and organized into categories for easy access. Next, a knowledge database should be created to store and document the feedback that is potentially useful for the organization. Finally, an automated system should be developed to alert the relevant stakeholders whenever new feedback is available.': 104, 'I apologize for missing our appointment and I understand how this might have caused you inconvenience. I take full responsibility for my actions and I promise to do my best to make it up to you.': 42, \"The prefix of 'uncooperative' is 'un-' which means not, and the suffix means 'cooperative'. Therefore, the word 'uncooperative' means 'not cooperative'.\": 44, 'Rock, paper, scissors, shoot! (Rock, Paper or Scissors are the input)': 24, 'The Inventive Pen.': 7, 'Possible activities that one could do in a city include visiting museums, parks, shopping centers, theaters, restaurants, and sightseeing.': 31, 'NicerShoes is an amazing online store with a huge selection of shoes. The prices are reasonable, the delivery is quick and efficient, and the customer service is excellent. I would definitely recommend NicerShoes to anyone looking for good quality, reasonably priced shoes.': 56, 'Flour, Baking powder, Cinnamon, Milk, Large Egg': 18, 'Visual interface, user experience, performance and scalability, security, testing, and compatibility with different devices.': 22, \"J'ai besoin d'aide.\": 11, 'False. Cats can taste sweet food, but they typically prefer savory sources of flavor.': 20, 'The sound was very loud.': 7, \"Gender equality is a major theme in the book 'A Doll's House.'\": 19, 'The use of social media has a profound impact on society both positively and negatively, with its applications ranging from facilitating communication to creating divisions within communities.': 33, '5 x 8 = 40, so the equation would be (5 x 8) + 10 = 50.': 31, 'One job where excellent problem-solving skills would be necessary is a software engineer. Software engineers need to be able to evaluate a problem, analyze the requirements, and develop an efficient solution using the appropriate programming languages and technologies. They must also possess the ability to think logically and devise creative solutions to any challenge they encounter.': 67, '1. N-Gram Modeling\\n2. Part-of-Speech Tagging\\n3. Constituency Parsing\\n4. Dependency Parsing\\n5. Named Entity Recognition\\n6. Word Embedding\\n7. Topic Modeling\\n8. Machine Translation\\n9. Text Summarization\\n10. Text-to-Speech Synthesis.': 87, 'Treatment  |  Effectiveness  | \\n-----------------------------------\\nTreatment 1  |  x  | \\nTreatment 2  |  y  | \\nTreatment 3  |  z  | \\nTreatment 4  |  a  | \\nTreatment 5  |  b  |': 79, 'Mount Everest (8848m), K2 (8611m), and Kangchenjunga (8586m).': 34, 'Sustainable development is a concept which advocates for the development of economies and societies in a way that meets present needs and needs of the future generations without compromising the natural resources and environment. It promotes the idea of using resources in a way that causes less damage to the environment and also encourages conserving natural resources through proper management, efficient use of resources, and renewable resources.': 81, 'Tranquility, serenity.': 9, 'Wind: Clarinet, Oboe\\nString: Violin': 14, 'Water cannot exist in a vacuum.': 8, 'I am powerful and capable of achieving anything I set my mind to.': 15, 'The recommended method for implementing password resets is by using a one-time token, also known as a one-time password (OTP). This token should be sent to the user via email or text message, and should be used to authenticate the user before allowing them to reset their password.': 62, 'Shopping list: cereal, 2% milk, large eggs, and extra large eggs.': 21, 'Mayor Accused of Embezzling Funds From City Coffers': 15, 'A possible diagnosis is abdmoninal pain caused by gastritis.': 16, 'Life is like the epic story of Star Wars: you will face obstacles, make tough decisions, and forge your own path. No matter what, you can always choose the path of courage and hope, and never give up.': 48, 'Tall and leafy.': 6, 'Machine learning is a type of artificial intelligence that focuses on building computer systems that learn by themselves. These systems don’t require explicit programming to create models or perform tasks; instead, they use large datasets to make predictions and automate tasks. By ingesting data and mining patterns, machine learning algorithms can detect complex relationships and iteratively improve their predictive accuracy.': 74, 'The cat was awake restlessly in the sun.': 11, 'She peered out the window.': 8, 'Sometimes I just need a jump start.': 9, 'Nature writing': 3, 'Here are three food items you can prepare with the ingredients in your kitchen:\\n1. Tomato, bell pepper and lettuce salad. \\n2. Grilled carrots with bell peppers and tomatoes. \\n3. Tomato and bell pepper soup.': 58, 'I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.': 89, 'A living algorithm is a model of a physical system that continuously learns from its environment in order to optimize its behaviors. It is an evolutionary algorithm that can adapt and self-improve in unpredictable environments. These algorithms are inspired by nature and are used to solve complex optimization tasks that are difficult for traditional algorithmic approaches.': 70, 'The code has one mistake. The \"i++\" line should not be indented, since it is not part of the for loop.': 29, 'I will build a predictive model using machine learning algorithms, such as naïve bayes, support vector machines, and random forests, based on the available customer demographic, purchase history and customer preference data. The model will help predict the likelihood of customer purchase.': 55, 'zxcvb932': 7, 'if (num1 > num2) {\\n  console.log(num1 + \" is greater than \" + num2);\\n} else {\\n  console.log(num1 + \" is not greater than \" + num2);\\n}': 53, 'The student wrote the thesis.': 7, 'A business is like a finely tuned machine. Just like a machine, it needs visionary leaders, dependable workers and well-oiled resources in order to run efficiently and produce successful results. Each individual has their role to play, and when everyone works together in harmony, the company flourishes and succeeds.': 66, 'A teapot - ceramic, intricately decorated, golden.': 16, 'The students have rapidly improved their literacy over the last year.': 14, 'The illusion of a glass of water is a visual trick that makes it appear as if the glass is half full or half empty, when in reality it is the same amount in both halves. This illusion has been studied extensively in the context of perception and cognition.': 56, 'I have been blissfully residing here for many years.': 14, 'Yes': 2, 'A successful business idea should have these characteristics: a unique selling proposition, the ability to meet a market need, potential for scalability, capital-efficiency, and realistic market potential. Additionally, the business should be able to be executed within a given budget and timeframe and should be able to provide a return on investment for its investors.': 69, 'A suitable topic for a presentation about the petroleum industry could be \"The Impact of the Petroleum Industry on the Global Economy\". This topic would explore how the oil and gas industry affects the global economy, covering topics such as job creation and economic growth, contribution to GDP, export of oil, and resource conservation. The presentation could also discuss how the industry is responding to the rise of renewable energy sources, and how this change will affect global markets.': 96, '[Start] \\n|\\nV\\nFill out job application \\n|\\nV\\nAttach relevant documents \\n|\\nV\\nSchedule job interview \\n|\\nV \\nAttend job interview\\n|\\nV\\nReceive job offer\\n|\\nV\\n[End]': 61, 'The thick canopy of the rainforest blocked out almost all of the sunlight, leaving the ground in perpetual shade. The air was damp and humid, and the humidity made it feel like the air was thick and viscous. It was as if breathing had become an effort in itself. Even the animals seemed to be holding their breath. Suddenly, a loud crash filled the air, and then all was still.': 88, '\"We all make mistakes sometimes, so please don\\'t feel too bad about this one.\"': 20, \"Creating a website for a local business requires a number of steps, including designing the site's layout and structure, writing content for the homepage and individual pages, incorporating features such as maps, contact forms, and appointment requests, and optimizing the site for search engines. Additionally, if the business is using the website to generate business, features such as e-commerce and payment processing need to be implemented. Lastly, the website must be tested and secured to ensure that the business's information is kept safe and the website is accessible to all potential customers.\": 116, 'Good customer service should be friendly, professional, timely, courteous, and informative.': 21, 'The pair of numbers with the greatest product is 0 and -4, which has a product of 0.': 24, \"One way for college students to save money is to take advantage of student discounts wherever possible. Many stores and online retailers offer discounts for students, so it's worth taking the time to look for them when making a purchase. Additionally, learning to budget and tracking spending is a great way to save money. Setting up a budget and then tracking expenses by noting all purchases helps to stay organized and keep expenses in check.\": 87, 'I feel abandoned and hollow, like a ship without its anchor.': 14, 'The job with the highest hourly pay rate is a surgeon, with an average hourly rate of $97.46.': 29, 'World War I, which was fought between 1914 and 1918, is considered to be the closest in terms of casualties, physical destruction, and global impacts. The two wars were instigated by aggressors and sparked off escalating hostilities which led to the eventual involvement of the major world powers at the time. Both wars featured heavily mechanized warfare and unprecedented mobilization of soldiers and resources resulting in unprecedented loss of life and destruction.': 103, 'Root Mean Squared Error (RMSE) is an error metric used in machine learning and data science to evaluate how well a model is performing on a given dataset. It measures the average absolute difference between the actual and predicted values. RMSE is the square root of the average squared difference between the predicted and actual values. It punishes large errors more heavily than small errors, making it a better measure for model performance than mean absolute error.': 92, '\"Fam\" is a popular urban slang term used to refer to one\\'s close friends.': 22, '- Host an online or in-person event to provide information and demonstrations of products or services. \\n- Launch a promotional campaign offering trial or discount offers to give potential customers the opportunity to experience the product or service.\\n- Create a referral program where customers who refer new customers receive an incentive.': 66, 'In my region, there are many pine trees. The most common types of pine trees are Eastern White Pine, Red Pine, and Jack Pine. These trees grow to a height of between 50-90 feet, and their needles are between 5-10 centimeters long. The larvae of a few species of moths feed on pine needles, and pinecones also provide food to birds and small mammals.': 98, 'The French Revolution was a period of political and social upheaval in France from 1789 to 1799.': 29, 'The three main symptoms of Coronavirus are: 1) Cough 2) Fever 3) Shortness of Breath or difficulty breathing. Other less common symptoms include fatigue, headache, sore throat, and loss of smell or taste.': 54, 'The five countries in Europe that have a monarchy are the United Kingdom, Andorra, Belgium, Monaco, and Liechtenstein.': 30, '181': 5, 'Observation.': 4, 'The mood of the text is foreboding.': 11, 'Setting up a local network requires understanding the different components involved. First, you need to check if your router supports a local network. Then, you need to determine the types of connections you need, such as wireless or direct. After that, you need to connect the router to the internet, if required. Once you have the router connected, you need to configure the network name and assign IP addresses. Finally, if desired, you can add additional security precautions to the network.': 98, 'Classify recipes into one of five categories: appetizers, entrees, desserts, drinks, and snacks.': 25, 'Verbs: walk\\nNouns: tree, cat, river': 15, 'A professional chef will cut a mango with a sharp knife, beginning by slicing off the stem end. Using the same knife, they will slice the mango lengthwise, getting as close to the pit as possible. Then the chef will use a spoon to scoop out the flesh. They can use the slices for dicing or cubes, or just enjoy the half without cutting further.': 82, 'The postman was singing while he walked in the late night traffic. He had an envelope tucked under his arm which he delivered to a kitchen on the way.': 33, 'Three marketing strategies could include digital marketing (such as SEO, social media, and email marketing), content marketing (such as blogging, webinars, and podcasts), and PR (such as press releases, media appearances, and event planning).': 51, 'def add_two_numbers(a, b):\\n    return a + b': 19, 'John (Present Simple: like) likes (Present Simple: like) the (No verb) blue (No verb) house (No verb) at (No verb) the (No verb) end (No verb) of (No verb) the (No verb) street (No verb).': 60, 'Archaeologist': 4, 'Small, tiny, diminutive': 8, 'The sentence is using a metaphor to compare the wind to a master.': 16, \"There once was a girl from the lake\\nWho enjoyed skating for fun 'n for sake\\nShe was a pro at the sport\\nAnd it quickly became her forte\\nAs she zipped around without a break!\": 46, 'Computer viruses are like a forest fire: both rapidly spread and can cause immense damage if not contained quickly.': 23, 'Ambition is like a lion fiercely driven to reach the pinnacle of success.': 20, 'Expressive, passionate, adventurous, reliable, and generous.': 15}\n",
      "ICL prompt complete\n",
      "Max number of tokens:  118\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Instruction: What is the maximum number of steps in a Fibonacci sequence?\n",
      " ### Input: No input.\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the maximum number of steps in a Fibonacci sequence?\n",
      "\n",
      "### Input:\n",
      "No input.\n",
      "\n",
      "### Response:\n",
      "The maximum number of steps in a Fibonacci sequence is 93.\n",
      " ### Output:\n",
      "REAL ANSWER:\n",
      " The maximum number of steps in a Fibonacci sequence is 93.\n",
      "PREDICTION:\n",
      " \n",
      "The maximum number of steps in a Fibonacci sequence is 93.\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------Another-------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "### Instruction: What is the definition of a Fibonacci sequence?\n",
      " ### Input: No input.\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the definition of a\n",
      "ICL prompt complete\n",
      "Max number of tokens:  156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  152\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  125\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  175\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  112\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  181\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  200\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  164\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  136\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  204\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  142\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  131\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  118\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  122\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  119\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  131\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  167\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  179\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  134\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  181\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  109\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  162\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  121\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  148\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  106\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  174\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  109\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  103\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  158\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  189\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Instruction: What is your opinion about the given concept?\n",
      " ### Input: Living a sustainable lifestyle\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is your opinion about the given concept?\n",
      "\n",
      "### Input:\n",
      "Living a sustainable lifestyle\n",
      "\n",
      "### Response:\n",
      "I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.\n",
      " ### Output:\n",
      "REAL ANSWER:\n",
      " I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.\n",
      "PREDICTION:\n",
      " \n",
      " I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.\n",
      " ### Score: 13.13\n",
      "\n",
      " # Conversational Prompt\n",
      " ```````````````````````````````````````````````````````````````````````````````````````````````````````\n",
      " ### Instruction: What is your opinion about the given concept?\n",
      " ### Input: Living a sustainable lifestyle (living sustainably; living a\n",
      "ICL prompt complete\n",
      "Max number of tokens:  170\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  155\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  153\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  166\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  102\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  196\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  161\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  188\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  216\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  121\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  203\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  192\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  122\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  166\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  198\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  154\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  130\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  198\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  125\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  182\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  119\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  146\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  123\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ICL prompt complete\n",
      "Max number of tokens:  118\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Instruction: Identify the starting and ending point of this sequence\n",
      " ### Input: 2, 4, 8, 16\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the starting and ending point of this sequence\n",
      "\n",
      "### Input:\n",
      "2, 4, 8, 16\n",
      "\n",
      "### Response:\n",
      "The starting point of the sequence is 2 and the ending point is 16. \n",
      " ### Output: The starting point of the sequence is 2 and the ending point is 16.\n",
      "### Instruction: What is the maximum number of steps in a Fibonacci sequence?\n",
      " ### Input: No input.\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the maximum number of steps in a Fibonacci sequence?\n",
      "\n",
      "### Input:\n",
      "No input.\n",
      "\n",
      "### Response:\n",
      "The maximum number of steps in a Fibonacci sequence is 93.\n",
      " ### Output:\n",
      "REAL ANSWER:\n",
      " The maximum number of steps in a Fibonacci sequence is 93.\n",
      "PREDICTION:\n",
      " \n",
      "1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89\n",
      " The maximum number of steps in a Fibonacci sequence is 93.\n",
      "### Instruction: Calculate the 50th term of the Fibonacci sequence.\n",
      " ### Input: No input.\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "ICL prompt complete\n",
      "Max number of tokens:  156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  152\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  125\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  175\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  112\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  181\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  200\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  164\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  136\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  204\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  142\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  131\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  118\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  122\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  119\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  131\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  167\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  179\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  134\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  181\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  109\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  162\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  121\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  148\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  106\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  174\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  109\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  103\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  158\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  189\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Instruction: Come up with three ways the following issue can be addressed.\n",
      " ### Input: Global climate change\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Come up with three ways the following issue can be addressed.\n",
      "\n",
      "### Input:\n",
      "Global climate change\n",
      "\n",
      "### Response:\n",
      "Three ways to address global climate change are reducing emissions by utilizing renewable energy sources like solar, wind, and hydro, conserving energy by increasing efficiency, and investing in research and development of new technologies to reduce the impact of climate change. \n",
      " ### Output: Three ways to address global climate change are reducing emissions by utilizing renewable energy sources like solar, wind, and hydro, conserving energy by increasing efficiency, and investing in research and development of new technologies to reduce the impact of climate change.\n",
      "### Instruction: What is your opinion about the given concept?\n",
      " ### Input: Living a sustainable lifestyle\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is your opinion about the given concept?\n",
      "\n",
      "### Input:\n",
      "Living a sustainable lifestyle\n",
      "\n",
      "### Response:\n",
      "I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.\n",
      " ### Output:\n",
      "REAL ANSWER:\n",
      " I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.\n",
      "PREDICTION:\n",
      " I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.\n",
      "ICL prompt complete\n",
      "Max number of tokens:  170\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  155\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  153\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  166\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  102\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  196\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  161\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  188\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  216\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  121\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  203\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  192\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  122\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  166\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  198\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  154\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  130\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  198\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  125\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  182\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  119\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  146\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  123\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ICL prompt complete\n",
      "Max number of tokens:  118\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Instruction: Identify the starting and ending point of this sequence\n",
      " ### Input: 2, 4, 8, 16\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the starting and ending point of this sequence\n",
      "\n",
      "### Input:\n",
      "2, 4, 8, 16\n",
      "\n",
      "### Response:\n",
      "The starting point of the sequence is 2 and the ending point is 16. \n",
      " ### Output: The starting point of the sequence is 2 and the ending point is 16.\n",
      "### Instruction: Generate the third term in the sequence 2, 5, 9, 14.\n",
      " ### Input: \n",
      " ### Text: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate the third term in the sequence 2, 5, 9, 14.\n",
      "\n",
      "### Response:\n",
      "18 \n",
      " ### Output: 18\n",
      "### Instruction: What is the maximum number of steps in a Fibonacci sequence?\n",
      " ### Input: No input.\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the maximum number of steps in a Fibonacci sequence?\n",
      "\n",
      "### Input:\n",
      "No input.\n",
      "\n",
      "### Response:\n",
      "The maximum number of steps in a Fibonacci sequence is 93.\n",
      " ### Output:\n",
      "REAL ANSWER:\n",
      " The maximum number of steps in a Fibonacci sequence is 93.\n",
      "PREDICTION:\n",
      " The maximum number of steps in a Fibonacci sequence is 93.\n",
      "### Instruction: How does a linear sequence differ from a geometric sequence?\n",
      " ### Input: No input.\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "How does a linear sequence differ from a geometric sequence?\n",
      "\n",
      "### Input:\n",
      "No input.\n",
      "\n",
      "### Response:\n",
      "A linear sequence has a constant ratio between terms, whereas\n",
      "ICL prompt complete\n",
      "Max number of tokens:  156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  152\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  125\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  175\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  112\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  181\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  200\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  164\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  136\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  204\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  142\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  131\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  118\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  122\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  119\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  131\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  167\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  179\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  134\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  181\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  109\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  162\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  121\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  148\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  106\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  174\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  109\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  103\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  158\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  189\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Instruction: Come up with three ways the following issue can be addressed.\n",
      " ### Input: Global climate change\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Come up with three ways the following issue can be addressed.\n",
      "\n",
      "### Input:\n",
      "Global climate change\n",
      "\n",
      "### Response:\n",
      "Three ways to address global climate change are reducing emissions by utilizing renewable energy sources like solar, wind, and hydro, conserving energy by increasing efficiency, and investing in research and development of new technologies to reduce the impact of climate change. \n",
      " ### Output: Three ways to address global climate change are reducing emissions by utilizing renewable energy sources like solar, wind, and hydro, conserving energy by increasing efficiency, and investing in research and development of new technologies to reduce the impact of climate change.\n",
      "### Instruction: Create a survey question to find out people's attitude toward recycling\n",
      " ### Input: \n",
      " ### Text: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Create a survey question to find out people's attitude toward recycling\n",
      "\n",
      "### Response:\n",
      "What is your attitude towards recycling? \n",
      "a) I strongly support it \n",
      "b) I support it\n",
      "c) I am neutral\n",
      "d) I oppose it\n",
      "e) I strongly oppose it \n",
      " ### Output: What is your attitude towards recycling? \n",
      "a) I strongly support it \n",
      "b) I support it\n",
      "c) I am neutral\n",
      "d) I oppose it\n",
      "e) I strongly oppose it\n",
      "### Instruction: What is your opinion about the given concept?\n",
      " ### Input: Living a sustainable lifestyle\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is your opinion about the given concept?\n",
      "\n",
      "### Input:\n",
      "Living a sustainable lifestyle\n",
      "\n",
      "### Response:\n",
      "I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.\n",
      " ### Output:\n",
      "REAL ANSWER:\n",
      " I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.\n",
      "PREDICTION:\n",
      " I believe that living a sustainable lifestyle is an important choice for the future of the planet. It is important to do our part to reduce our consumption and waste, as well as to find ways to use renewable energy sources such as solar, wind, and geothermal. Sustainability also includes reducing our reliance on non-renewable resources and making informed decisions about our purchases with regard to both environmental and social considerations.\n",
      "### Instruction: What is the cause of the problem you're going through? Are there any related situations?\n",
      " ### Input:\n",
      " ### Text: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the cause of the problem you're going through? Are there any related situations?\n",
      "\n",
      "### Response:\n",
      "The cause of my problem is that\n",
      "ICL prompt complete\n",
      "Max number of tokens:  170\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  155\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  153\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  166\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  102\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  196\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  161\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  188\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  216\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  121\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  203\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  192\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  122\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  166\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  198\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  129\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  154\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  130\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  111\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  198\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  125\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  182\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  119\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  116\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  146\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  123\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Max number of tokens:  115\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_mist\n",
    "model = model_mist\n",
    "\n",
    "data = load_dataset('tatsu-lab/alpaca')['train']\n",
    "\n",
    "# data = filter_icl(data, max_num_egs, tokenizer_plain)\n",
    "\n",
    "max_num_egs =  3   #natural instructions are just too big\n",
    "\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "def filter_example(example):\n",
    "    return count_tokens(tokenizer, f\"### Instruction: {example['instruction']}\\n ### Input: {example['input']}\\n ### Text: {example['text']} \\n ### Output: {example['output']}\") <= 300\n",
    "\n",
    "data = data.filter(filter_example)\n",
    "\n",
    "\n",
    "train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test'].select(range(100))\n",
    "\n",
    "# train_dataset = data['train']\n",
    "# test_dataset = data['test'].select(range(100))\n",
    "\n",
    "\n",
    "icl_method = 'similarity'\n",
    "model_name = 'mistral'\n",
    "ds_name = 'alpaca'\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name=\"alpaca\")\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "max_token_dict = {}\n",
    "for eg in test_dataset:\n",
    "    max_token_dict[eg['output']] = count_tokens(tokenizer, eg['output'])\n",
    "print(max_token_dict)\n",
    "\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "for i in range(max_num_egs):\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model, tokenizer, i, model_name=model_name, ds_name=ds_name, method=icl_method, max_tokens_dict=max_token_dict)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    print(order)\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order= order) #set order to mean of real values\n",
    "    bleurt_score = bleurt.compute(predictions=preds, references=reals)\n",
    "    avg_bleurt = sum(bleurt_score['scores'])/len(bleurt_score['scores'])\n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations':i, 'bert_score' : float(average_F1), 'bleu_score': bleu_score['bleu'], 'bleurt_score' : avg_bleurt})\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/{icl_method}/icl_results_{ds_name}_{model_name}.csv', index=False)\n",
    "\n",
    "# plt.figure(figsize=(10, 2))\n",
    "# plt.plot(range(max_num_egs), bert_scores) \n",
    "# plt.xlabel('Number of examples') \n",
    "# plt.ylabel('BERT F1 Score') \n",
    "# plt.title('BERT F1 Score vs Number of Examples') \n",
    "# plt.xticks(range(max_num_egs))\n",
    "# plt.savefig('BERT_scores_icl_ni.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(int(sum(len(s) for s in refs)/len(refs)))\n",
    "# test = bleu.compute(predictions=['No', 'Yes', 'Yes', 'yes', 'Yes', 'yes', 'yes', 'No', 'yes', 'No'],\n",
    "#                     references=['No.', 'Yes.', 'No.', 'Yes.', 'No.', 'Yes.', 'No.', 'Yes.', 'No.', 'Yes.'], max_order=int(sum(len(s) for s in refs)/len(refs)))\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Medical MCQ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set:  100\n",
      "Length of train set 6086\n",
      "ICL prompt complete\n",
      "20 160\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 35-year-old woman comes to your office with a variety of complaints. As part of her evaluation, she undergoes laboratory testing which reveals the presence of anti-centromere antibodies. All of the following symptoms and signs would be expected to be present EXCEPT:? \n",
      "{'A': 'Pallor, cyanosis, and erythema of the hands', 'B': 'Calcium deposits on digits', 'C': 'Blanching vascular abnormalities', 'D': 'Hypercoagulable state', 'E': 'Heartburn and regurgitation'},\n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " D: Hypercoagulable state\n",
      "PREDICTION:\n",
      " D\n",
      " ### Explanation:\n",
      " ### Answer: D\n",
      " ### Explanation:\n",
      " ###\n",
      "ICL prompt complete\n",
      "15 188\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 309\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 386\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 334\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 478\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "28 252\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 346\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 289\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 297\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 284\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 198\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 294\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "22 323\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "15 168\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 277\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "32 423\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 183\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 298\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 309\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "15 441\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 173\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 236\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 373\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "30 341\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "31 242\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "61 445\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 189\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "22 186\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 287\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 303\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "27 204\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 217\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 328\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 201\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 571\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 312\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 182\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 365\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "22 216\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 244\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "32 241\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 292\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 312\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 226\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 308\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "25 251\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "28 312\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 241\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 31 year-old-man presents to an urgent care clinic with symptoms of lower abdominal pain, bloating, bloody diarrhea, and fullness, all of which have become more frequent over the last 3 months. His vital signs are as follows: blood pressure is 121/81 mm Hg, heart rate is 87/min, and respiratory rate is 15/min. Rectal examination reveals a small amount of bright red blood. Lower endoscopy is performed, showing extensive mucosal erythema, induration, and pseudopolyps extending from the rectum to the splenic flexure. Given the following options, what is the definitive treatment for this patient’s underlying disease?? \n",
      "{'A': 'Sulfasalazine', 'B': 'Mesalamine', 'C': 'Systemic corticosteroids', 'D': 'Azathioprine', 'E': 'Total proctocolectomy'},\n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " E: Total proctocolectomy\n",
      "PREDICTION:\n",
      " C\n",
      "\n",
      " ### Question: Q:A 31 year-old-man presents to\n",
      "ICL prompt complete\n",
      "19 226\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 242\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 269\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 295\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 451\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 218\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 257\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 276\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 182\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 227\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 326\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 244\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 293\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 357\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 301\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "33 387\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 394\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "15 141\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 247\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "30 379\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 215\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 204\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 305\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 200\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 221\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 329\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "25 229\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 299\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 348\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 431\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 251\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 347\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "29 277\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 222\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 339\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 221\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 263\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 312\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 219\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 190\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 470\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "31 252\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 293\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 270\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 328\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "28 196\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 455\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "DOING BLEURT\n",
      "DONE BLEURT\n",
      "ICL prompt complete\n",
      "20 392\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 51-year-old white female presents to her primary care physician for a regular check-up. She endorses eating a healthy diet with a balance of meat and vegetables. She also states that she has a glass of wine each night with dinner. As part of the evaluation, a complete blood count and blood smear were performed and are remarkable for: Hemoglobin 8.7 g/dL, Hematocrit 27%, MCV 111 fL, and a smear showing macrocytes and several hypersegmented neutrophils. Suspecting an autoimmune condition with anti-intrinsic factor antibodies, what other finding might you expect in this patient?? \n",
      "{'A': 'High serum TSH', 'B': 'Psorasis', 'C': 'Cheilosis', 'D': 'Bleeding gums', 'E': 'Abdominal colic'},\n",
      " ### Answer: A: High serum TSH\n",
      "### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 35-year-old woman comes to your office with a variety of complaints. As part of her evaluation, she undergoes laboratory testing which reveals the presence of anti-centromere antibodies. All of the following symptoms and signs would be expected to be present EXCEPT:? \n",
      "{'A': 'Pallor, cyanosis, and erythema of the hands', 'B': 'Calcium deposits on digits', 'C': 'Blanching vascular abnormalities', 'D': 'Hypercoagulable state', 'E': 'Heartburn and regurgitation'},\n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " D: Hypercoagulable state\n",
      "PREDICTION:\n",
      " E: Heartburn and regurgitation\n",
      "### Task: Please answer with one of the option in\n",
      "ICL prompt complete\n",
      "15 413\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 637\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 670\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 601\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 743\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "28 514\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 581\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 521\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 576\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 563\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 336\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 519\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "22 608\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "15 417\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 585\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "32 629\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 384\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 547\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 629\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "15 676\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 379\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 466\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 682\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "30 692\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "31 521\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "61 694\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 463\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "22 388\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 578\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 594\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "27 415\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 432\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 590\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 456\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 656\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 424\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 877\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 596\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 469\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 623\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "22 474\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 528\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "32 447\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 599\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 580\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 431\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 512\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "25 516\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "28 639\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 469\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 30-year-old man comes to the physician because of an episode of bloody vomiting this morning and a 1-week history of burning upper abdominal pain. Two weeks ago, he sustained a head injury and was in a coma for 3 days. An endoscopy shows multiple, shallow hemorrhagic lesions predominantly in the gastric fundus and greater curvature. Biopsies show patchy loss of epithelium and an acute inflammatory infiltrate in the lamina propria that does not extend beyond the muscularis mucosa. Which of the following is the most likely diagnosis?? \n",
      "{'A': 'Type B gastritis', 'B': 'Dieulafoy lesion', 'C': 'Cushing ulcer', 'D': 'Penetrating ulcer', 'E': 'Erosive gastritis'},\n",
      " ### Answer: E: Erosive gastritis\n",
      "### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 31 year-old-man presents to an urgent care clinic with symptoms of lower abdominal pain, bloating, bloody diarrhea, and fullness, all of which have become more frequent over the last 3 months. His vital signs are as follows: blood pressure is 121/81 mm Hg, heart rate is 87/min, and respiratory rate is 15/min. Rectal examination reveals a small amount of bright red blood. Lower endoscopy is performed, showing extensive mucosal erythema, induration, and pseudopolyps extending from the rectum to the splenic flexure. Given the following options, what is the definitive treatment for this patient’s underlying disease?? \n",
      "{'A': 'Sulfasalazine', 'B': 'Mesalamine', 'C': 'Systemic corticosteroids', 'D': 'Azathioprine', 'E': 'Total proctocolectomy'},\n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " E: Total proctocolectomy\n",
      "PREDICTION:\n",
      " E: Total proctocolectomy\n",
      "### Task: Please answer with one of the option\n",
      "ICL prompt complete\n",
      "19 458\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 521\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 472\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 593\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 719\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 475\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 542\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 457\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 603\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 387\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 508\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 609\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 521\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 561\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 641\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 590\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "33 643\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 722\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "15 307\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 536\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "30 652\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 493\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 394\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 594\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 419\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 400\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 595\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "25 491\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 626\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 653\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 759\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 444\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 607\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "29 557\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 531\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 648\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 423\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 568\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 555\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 498\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 349\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 391\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 798\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "31 425\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 640\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 520\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 591\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "28 475\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 704\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "DOING BLEURT\n",
      "DONE BLEURT\n",
      "ICL prompt complete\n",
      "20 624\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 51-year-old white female presents to her primary care physician for a regular check-up. She endorses eating a healthy diet with a balance of meat and vegetables. She also states that she has a glass of wine each night with dinner. As part of the evaluation, a complete blood count and blood smear were performed and are remarkable for: Hemoglobin 8.7 g/dL, Hematocrit 27%, MCV 111 fL, and a smear showing macrocytes and several hypersegmented neutrophils. Suspecting an autoimmune condition with anti-intrinsic factor antibodies, what other finding might you expect in this patient?? \n",
      "{'A': 'High serum TSH', 'B': 'Psorasis', 'C': 'Cheilosis', 'D': 'Bleeding gums', 'E': 'Abdominal colic'},\n",
      " ### Answer: A: High serum TSH\n",
      "### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 40-year-old man presents to a clinic in Michigan in December complaining of painful blue fingers and toes. He also complains of numbness and tingling. The patient’s vital signs are within normal limits, and his symptoms typically disappear when he comes back into a warm room. The patient also notes that he recently moved to the area from Arizona and had recently recovered from a viral infection in which he had a low-grade fever and severe lymphadenopathy. Which of the following tests would most likely be positive in this patient?? \n",
      "{'A': 'Indirect Coomb’s test', 'B': 'Direct Coomb’s test with anti-IgG reagent', 'C': 'Direct Coomb’s test with anti-C3 reagent', 'D': 'Anti-centromere antibody', 'E': 'Anti-Ro antibody'},\n",
      " ### Answer: C: Direct Coomb’s test with anti-C3 reagent\n",
      "### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 35-year-old woman comes to your office with a variety of complaints. As part of her evaluation, she undergoes laboratory testing which reveals the presence of anti-centromere antibodies. All of the following symptoms and signs would be expected to be present EXCEPT:? \n",
      "{'A': 'Pallor, cyanosis, and erythema of the hands', 'B': 'Calcium deposits on digits', 'C': 'Blanching vascular abnormalities', 'D': 'Hypercoagulable state', 'E': 'Heartburn and regurgitation'},\n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " D: Hypercoagulable state\n",
      "PREDICTION:\n",
      " E: Heartburn and regurgitation\n",
      "### Task: Please answer with one of the option in\n",
      "ICL prompt complete\n",
      "15 692\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 899\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "28 759\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 786\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 760\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 848\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 863\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 518\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 804\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "22 853\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "15 617\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 869\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "32 892\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 673\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 777\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 561\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 744\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "31 812\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 681\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "22 693\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 841\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 822\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "27 603\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 705\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 675\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 650\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 852\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 749\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 888\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "22 715\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 763\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "32 745\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 884\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 659\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 777\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "25 749\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 731\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 30-year-old man comes to the physician because of an episode of bloody vomiting this morning and a 1-week history of burning upper abdominal pain. Two weeks ago, he sustained a head injury and was in a coma for 3 days. An endoscopy shows multiple, shallow hemorrhagic lesions predominantly in the gastric fundus and greater curvature. Biopsies show patchy loss of epithelium and an acute inflammatory infiltrate in the lamina propria that does not extend beyond the muscularis mucosa. Which of the following is the most likely diagnosis?? \n",
      "{'A': 'Type B gastritis', 'B': 'Dieulafoy lesion', 'C': 'Cushing ulcer', 'D': 'Penetrating ulcer', 'E': 'Erosive gastritis'},\n",
      " ### Answer: E: Erosive gastritis\n",
      "### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 75-year-old man is brought to the emergency department after 2 days of severe diffuse abdominal pain, nausea, vomiting, and lack of bowel movements, which has led him to stop eating. He has a history of type-2 diabetes mellitus, hypertension, and chronic pulmonary obstructive disease. Upon admission, his vital signs are within normal limits and physical examination shows diffuse abdominal tenderness, distention, lack of bowel sounds, and an empty rectal ampulla. After initial fluid therapy and correction of moderate hypokalemia, the patient’s condition shows mild improvement. His abdominal plain film is taken and shown. Which of the following is the most appropriate concomitant approach?? \n",
      "{'A': 'Initiate pain management with morphine', 'B': 'Initiate intravenous metoclopramide', 'C': 'Nasogastric decompression', 'D': 'Exploratory surgery', 'E': 'Gastrografin enema'},\n",
      " ### Answer: C: Nasogastric decompression\n",
      "### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 31 year-old-man presents to an urgent care clinic with symptoms of lower abdominal pain, bloating, bloody diarrhea, and fullness, all of which have become more frequent over the last 3 months. His vital signs are as follows: blood pressure is 121/81 mm Hg, heart rate is 87/min, and respiratory rate is 15/min. Rectal examination reveals a small amount of bright red blood. Lower endoscopy is performed, showing extensive mucosal erythema, induration, and pseudopolyps extending from the rectum to the splenic flexure. Given the following options, what is the definitive treatment for this patient’s underlying disease?? \n",
      "{'A': 'Sulfasalazine', 'B': 'Mesalamine', 'C': 'Systemic corticosteroids', 'D': 'Azathioprine', 'E': 'Total proctocolectomy'},\n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " E: Total proctocolectomy\n",
      "PREDICTION:\n",
      " E: Total proctocolectomy\n",
      "### Task: Please answer with one of the option\n",
      "ICL prompt complete\n",
      "19 786\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 753\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 810\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 853\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 732\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 827\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 738\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 864\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 569\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 743\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 877\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 784\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 777\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 890\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "33 878\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "15 538\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 768\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "30 852\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 723\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 687\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 843\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 721\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "20 605\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "25 766\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 831\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 678\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "23 863\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "29 819\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "19 836\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 707\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 842\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "24 772\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 753\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "17 483\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 593\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "31 627\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "16 868\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "18 799\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "21 872\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "28 716\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "DOING BLEURT\n",
      "DONE BLEURT\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "tokenizer = tokenizer_gpt2\n",
    "model = model_gpt2\n",
    "\n",
    "max_num_egs = 3\n",
    "\n",
    "data = load_dataset('medalpaca/medical_meadow_medqa')['train']\n",
    "train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test'].select(range(100))\n",
    "\n",
    "def filter_example(example):\n",
    "    return count_tokens(tokenizer, f\"### Task: {example['instruction']}\\n ### Question: {example['input']}\\n ### Answer: {example['output']}\") <= 300\n",
    "\n",
    "train_dataset = train_dataset.filter(filter_example)\n",
    "\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name='medmcq')\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "icl_method = 'similarity'\n",
    "model_name = 'gpt2_small'\n",
    "ds_name = 'medmcq'\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "\n",
    "\n",
    "for i in range(max_num_egs):\n",
    "    accuracy = 0\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model_mist, tokenizer_mist, i, model_name=model_name, ds_name=ds_name, method=icl_method)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    print(\"order: \", order)\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order=order)\n",
    "    for r,p in zip(reals, preds):\n",
    "        if len(p.strip()) != 0:\n",
    "            if r.strip()[0] == p.strip()[0]:\n",
    "                accuracy+=1\n",
    "    accuracy = accuracy/len(preds)\n",
    "    print(\"DOING BLEURT\")\n",
    "    bleurt_score = bleurt.compute(predictions=preds, references=reals)\n",
    "    print(\"DONE BLEURT\")\n",
    "    avg_bleurt = sum(bleurt_score['scores'])/len(bleurt_score['scores'])\n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations' : i, 'bert_score' : float(average_F1), 'bleu_score' : bleu_score['bleu'], 'accuracy':accuracy, 'bleurt_score' : avg_bleurt})\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/{icl_method}/icl_results_{ds_name}_{model_name}.csv', index=False)\n",
    "\n",
    "# plt.figure(figsize=(10, 2))\n",
    "# plt.plot(range(max_num_egs), bert_scores) \n",
    "# plt.xlabel('Number of examples') \n",
    "# plt.ylabel('BERT F1 Score')\n",
    "# plt.title('BERT F1 Score vs Number of Examples') \n",
    "# plt.xticks(range(max_num_egs))\n",
    "# plt.savefig('BERT_scores_icl_medqa.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/icl_results_{ds_name}_{icl_method}_{model_name}.csv', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Transcript Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set:  100\n",
      "Length of train set 4618\n",
      "ICL prompt complete\n",
      "11 125\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Text:  Mark Lipacis,  Jefferies LLC - Analyst    [4]  That's very helpful, thank you.  And then, last question. On the new  so, you're just starting to ship Pascal now.  I guess my understanding is that historically as you're shipping a new product, the yields have opportunity for improvement, and the more volume you ship the more you climb down the yield curve. What classically happens to here on the yield?  And, does that positively impact gross margins over the next three or four quarters? Thank you.\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " positive\n",
      "PREDICTION:\n",
      "            \n",
      "ICL prompt complete\n",
      "11 244\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 107\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 59\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 483\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 134\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 227\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 213\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 262\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 110\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 71\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 339\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 58\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 181\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 629\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 130\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 202\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 332\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 695\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 165\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 285\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 51\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 52\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 79\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 79\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 335\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 229\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 179\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 212\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 256\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 178\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 188\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 322\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 79\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 251\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 406\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 167\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 79\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 215\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 148\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 110\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 81\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 83\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 184\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Text:  Colette Kress,  NVIDIA Corporation - EVP & CFO    [28]  Yes, Steven, thanks so much for the question. Our inventory levels that we are holding here, they are definitely going to swing a bit in terms of the mix, in terms of our platforms. But what we have right now, we do have a very healthy level of inventory. And we have a great team of people managing all of those different pieces, both for the channel, for our partners, and definitely for what we need to ship going forward.  So I don't think we look at a number to exactly optimize in any single one quarter, as we do make sure that we are prepared for the platforms coming down the pipeline, as well as what customers need. But you are correct, it is probably at a fairly healthy low level at this time.\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " positive\n",
      "PREDICTION:\n",
      "   NVIDIA Corporation - EVP & CFO  \n",
      "ICL prompt complete\n",
      "11 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 79\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 174\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 285\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 212\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 110\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 112\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 140\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 208\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 84\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 158\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 52\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 134\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 130\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 208\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 101\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 218\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 67\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 115\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 181\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 263\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 74\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 100\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 182\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 517\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 131\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 150\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 162\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 124\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 55\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 51\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 225\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 60\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 65\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 57\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 95\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 49\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 71\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 56\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "DOING BLEURT\n",
      "DONE BLEURT\n",
      "ICL prompt complete\n",
      "11 298\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Text: I think, if we look at it from an overall standpoint, in Q2, we did 41%. In the third quarter in a row, 41% gross margin. And in Q3, you're right that the decline in semi-custom, there is benefit to the margin. And the margin guide for Q3, that's approximately 43%. I can tell you that the richer product mix, especially with the new products ramping in Q3, are going to drive the gross margin. Although there is a benefit from the decline of semi-custom also, the margin benefit is more weighted towards the non-semi-custom business, and that's where we end up with the 43% in Q3. We've also updated our guidance for 2019 and now are projecting 42% for the year 2019.\n",
      " ### Targets: negative\n",
      "### Text:  Mark Lipacis,  Jefferies LLC - Analyst    [4]  That's very helpful, thank you.  And then, last question. On the new  so, you're just starting to ship Pascal now.  I guess my understanding is that historically as you're shipping a new product, the yields have opportunity for improvement, and the more volume you ship the more you climb down the yield curve. What classically happens to here on the yield?  And, does that positively impact gross margins over the next three or four quarters? Thank you.\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " positive\n",
      "PREDICTION:\n",
      "  negative\n",
      "### Text:  Jefferies LLC - Analyst\n",
      "ICL prompt complete\n",
      "11 442\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 304\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 205\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 341\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 257\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 681\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 332\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 346\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 168\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 329\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 550\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 490\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 137\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 581\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 349\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 315\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 701\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 235\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 289\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 620\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 390\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 419\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 203\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 106\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 593\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 426\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 336\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 391\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 424\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 385\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 282\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 388\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 231\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 171\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 478\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 283\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 171\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 321\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 270\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 283\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 135\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 317\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 372\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Text: Sure, Chris. So I think as has been the case for a few quarters now, there's actually a fair amount of tightness across that  across those 3 channels that you mentioned. So it would be hard to distinguish one from the other relative to any nuances there. I don't think there's an inventory issue. Certainly, if you actually take a look at inventory levels that are reported, which are typically financial numbers, and adjust those for dollar costs of how pricing has changed over the course of the year, you do get a bit of a different perspective on inventory, as reported by a variety of customers and channel partners in those areas, but the environment continues to be strong. The supply-demand circumstances continue to be fairly tight, and we're working very closely with our customers to make sure that we stay in close sync with them as they think about their plans going forward.\n",
      " ### Targets: positive\n",
      "### Text:  Colette Kress,  NVIDIA Corporation - EVP & CFO    [28]  Yes, Steven, thanks so much for the question. Our inventory levels that we are holding here, they are definitely going to swing a bit in terms of the mix, in terms of our platforms. But what we have right now, we do have a very healthy level of inventory. And we have a great team of people managing all of those different pieces, both for the channel, for our partners, and definitely for what we need to ship going forward.  So I don't think we look at a number to exactly optimize in any single one quarter, as we do make sure that we are prepared for the platforms coming down the pipeline, as well as what customers need. But you are correct, it is probably at a fairly healthy low level at this time.\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " positive\n",
      "PREDICTION:\n",
      "  positive\n",
      "### Text:  Colette Kress,\n",
      "ICL prompt complete\n",
      "11 246\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 372\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 482\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 359\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 290\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 392\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 304\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 305\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 392\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 332\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 418\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 329\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 352\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 106\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 312\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 261\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 167\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 264\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 418\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 211\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 398\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 196\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 261\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 310\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 526\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 293\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 254\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 354\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 811\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 257\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 214\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 228\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 312\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 113\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 373\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 241\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 447\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 128\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 338\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 340\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 304\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 230\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 242\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 141\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 137\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 117\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "DOING BLEURT\n",
      "DONE BLEURT\n",
      "ICL prompt complete\n",
      "11 430\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Text: I think, if we look at it from an overall standpoint, in Q2, we did 41%. In the third quarter in a row, 41% gross margin. And in Q3, you're right that the decline in semi-custom, there is benefit to the margin. And the margin guide for Q3, that's approximately 43%. I can tell you that the richer product mix, especially with the new products ramping in Q3, are going to drive the gross margin. Although there is a benefit from the decline of semi-custom also, the margin benefit is more weighted towards the non-semi-custom business, and that's where we end up with the 43% in Q3. We've also updated our guidance for 2019 and now are projecting 42% for the year 2019.\n",
      " ### Targets: negative\n",
      "### Text:  Stacy Aaron Rasgon,  Sanford C. Bernstein & Co., LLC., Research Division - Senior Analyst    [9]  I wanted to follow-up on that 10-nanometer point. So as the volume production pushes out into 2019, given you understand the yield issue supposedly, is this a first half kind of push out? Or does it push out into the second half? And when it actually does ramp, do you think it actually will be the current 10-nanometer process that's shipping? Or will that be like slipping out to like 10, 10 nanometers plus potentially?\n",
      " ### Targets: positive\n",
      "### Text:  Mark Lipacis,  Jefferies LLC - Analyst    [4]  That's very helpful, thank you.  And then, last question. On the new  so, you're just starting to ship Pascal now.  I guess my understanding is that historically as you're shipping a new product, the yields have opportunity for improvement, and the more volume you ship the more you climb down the yield curve. What classically happens to here on the yield?  And, does that positively impact gross margins over the next three or four quarters? Thank you.\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " positive\n",
      "PREDICTION:\n",
      "  negative\n",
      "### Text:  Mark Lipacis,\n",
      "ICL prompt complete\n",
      "11 514\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 457\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 333\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 493\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 437\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 753\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 512\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 492\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 252\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 521\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 694\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 387\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 670\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 395\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 698\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 526\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 203\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 472\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 893\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 353\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 461\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 773\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 558\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 653\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 280\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 241\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 241\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 773\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 582\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 509\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 616\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 617\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 575\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 454\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 532\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 425\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 390\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 441\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 575\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 375\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 259\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 566\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 362\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 443\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 369\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 413\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 488\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Text: Sure, Chris. So I think as has been the case for a few quarters now, there's actually a fair amount of tightness across that  across those 3 channels that you mentioned. So it would be hard to distinguish one from the other relative to any nuances there. I don't think there's an inventory issue. Certainly, if you actually take a look at inventory levels that are reported, which are typically financial numbers, and adjust those for dollar costs of how pricing has changed over the course of the year, you do get a bit of a different perspective on inventory, as reported by a variety of customers and channel partners in those areas, but the environment continues to be strong. The supply-demand circumstances continue to be fairly tight, and we're working very closely with our customers to make sure that we stay in close sync with them as they think about their plans going forward.\n",
      " ### Targets: positive\n",
      "### Text: Yes. No, I hear your point. One of the things that we mentioned is we are going to be producing in order to build inventory levels back up in the year. And so in the second half of the year, we would expect to be able to bring both our server products and most importantly, our PC products back to a more normalized inventory level. So we are  being up in the high single digits is meant to allow us to not only satisfy our customers but also rebuild the inventory. So your math is correct.\n",
      " ### Targets: positive\n",
      "### Text:  Colette Kress,  NVIDIA Corporation - EVP & CFO    [28]  Yes, Steven, thanks so much for the question. Our inventory levels that we are holding here, they are definitely going to swing a bit in terms of the mix, in terms of our platforms. But what we have right now, we do have a very healthy level of inventory. And we have a great team of people managing all of those different pieces, both for the channel, for our partners, and definitely for what we need to ship going forward.  So I don't think we look at a number to exactly optimize in any single one quarter, as we do make sure that we are prepared for the platforms coming down the pipeline, as well as what customers need. But you are correct, it is probably at a fairly healthy low level at this time.\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " positive\n",
      "PREDICTION:\n",
      "  positive\n",
      "### Text:  Colette Kress,\n",
      "ICL prompt complete\n",
      "11 335\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 241\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 552\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 654\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 453\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 488\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 509\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 457\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 439\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 574\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 557\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 628\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 507\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 444\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 399\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 441\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 269\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 398\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 628\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 436\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 456\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 290\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 371\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 429\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 820\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 389\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 420\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 325\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 561\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 371\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 462\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 438\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 203\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 517\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 337\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 544\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 220\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 432\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 471\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 457\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 422\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 336\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 229\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 220\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "11 247\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "DOING BLEURT\n",
      "DONE BLEURT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_num_egs = 3\n",
    "\n",
    "data = load_dataset('jlh-ibm/earnings_call', 'transcript-sentiment')['train']\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test'].select(range(100))\n",
    "\n",
    "tokenizer = tokenizer_gpt2\n",
    "model = model_gpt2\n",
    "\n",
    "def filter_example(example):\n",
    "    return count_tokens(tokenizer, f\"### Text: {example['text']}\\n ### Targets: {example['label']}\") <= 300\n",
    "\n",
    "train_dataset = train_dataset.filter(filter_example)\n",
    "\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name='finance_sent')\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "icl_method = 'similarity'\n",
    "model_name = 'gpt2_small'\n",
    "ds_name = 'finance_sent'\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "\n",
    "\n",
    "for i in range(max_num_egs):\n",
    "    accuracy = 0\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model, tokenizer, i, model_name=model_name, ds_name=ds_name, method=icl_method)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    print(\"order: \", order)\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order=order)\n",
    "    for r,p in zip(reals, preds):\n",
    "        if len(p.strip()) != 0:\n",
    "            if r.strip()[0] == p.strip()[0]:\n",
    "                accuracy+=1\n",
    "    accuracy = accuracy/len(preds)\n",
    "    print(\"DOING BLEURT\")\n",
    "    bleurt_score = bleurt.compute(predictions=preds, references=reals)\n",
    "    print(\"DONE BLEURT\")\n",
    "    avg_bleurt = sum(bleurt_score['scores'])/len(bleurt_score['scores'])\n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations' : i, 'bert_score' : float(average_F1), 'bleu_score' : bleu_score['bleu'], 'accuracy':accuracy, 'bleurt' : avg_bleurt})\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/{icl_method}/icl_results_{ds_name}_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Medicine QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15549\n",
      "Length of test set:  100\n",
      "Length of train set 12439\n",
      "ICL prompt complete\n",
      "152 36\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is anencephaly inherited ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Most cases of anencephaly are sporadic, which means they occur in people with no history of the disorder in their family. A small percentage of cases have been reported to run in families; however, the condition does not have a clear pattern of inheritance.\n",
      "PREDICTION:\n",
      "                                                                                                                                                         \n",
      "ICL prompt complete\n",
      "158 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "182 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "190 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "155 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "172 48\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "155 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "158 36\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "161 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "159 52\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "169 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "151 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 47\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 36\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 46\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "187 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 52\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 44\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "173 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 56\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 45\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 43\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 36\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "160 42\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "158 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "153 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "151 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "148 45\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "153 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "156 51\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 43\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "185 42\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "161 49\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 48\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "164 44\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "175 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 50\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Parasites - Fascioliasis (Fasciola Infection) ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Fascioliasis is an infectious disease caused by Fasciola parasites, which are flat worms referred to as liver flukes. The adult (mature) flukes are found in the bile ducts and liver of infected people and animals, such as sheep and cattle. In general, fascioliasis is more common in livestock and other animals than in people.\n",
      "PREDICTION:\n",
      "                                                                                                                                                                                  \n",
      "ICL prompt complete\n",
      "184 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "160 42\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "161 45\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 36\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 45\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "149 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "169 43\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "173 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 43\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 50\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "157 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "191 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "175 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "202 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "160 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "159 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "150 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "169 64\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 47\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "164 36\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "183 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 42\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 42\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "188 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "179 59\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 44\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 42\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "164 44\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "158 41\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "146 48\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "154 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 37\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "172 40\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "163 38\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "178 34\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "179 50\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "DOING BLEURT\n",
      "DONE BLEURT\n",
      "ICL prompt complete\n",
      "152 148\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is Fatal familial insomnia inherited ?\n",
      "    ### Response:\n",
      "    How is fatal familial insomnia inherited? Fatal familial insomnia (FFI) is inherited in an autosomal dominant manner. This means that to be affected, a person only needs a change (mutation) in one copy of the responsible gene in each cell. In some cases, an affected person inherits the mutation from an affected parent.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is anencephaly inherited ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Most cases of anencephaly are sporadic, which means they occur in people with no history of the disorder in their family. A small percentage of cases have been reported to run in families; however, the condition does not have a clear pattern of inheritance.\n",
      "PREDICTION:\n",
      " \n",
      "    How is anencephaly inherited? Anencephaly is inherited in an autosomal dominant manner. This means that to be affected, a person only needs a change (mutation) in one copy of the responsible gene in each cell. In some cases, an affected person inherits the mutation from an affected parent.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:    Is anencephaly inherited?\n",
      "    ### Response:\n",
      "    How is anencephaly inherited? Anencephaly is inherited in an autosomal dominant manner. This means that to be affected, a person only needs a change (mutation)\n",
      "ICL prompt complete\n",
      "158 160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 161\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "182 148\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "190 138\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "155 153\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 146\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "172 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 137\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "155 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "158 144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "161 139\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 140\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "159 156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "169 144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "151 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 167\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 128\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 137\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 146\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 174\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "187 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 194\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 137\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "173 152\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 140\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 170\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 165\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "160 143\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "158 153\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "153 156\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 163\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 165\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "151 135\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "148 178\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "153 144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "156 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 147\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "185 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "161 169\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 147\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 147\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "164 159\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "175 153\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 155\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 149\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What are the treatments for protein S deficiency ?\n",
      "    ### Response:\n",
      "    These resources address the diagnosis or management of protein S deficiency:  - Genetic Testing Registry: Protein S deficiency  - MedlinePlus Encyclopedia: Congenital Protein C or S Deficiency  - MedlinePlus Encyclopedia: Necrosis  - MedlinePlus Encyclopedi\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Parasites - Fascioliasis (Fasciola Infection) ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Fascioliasis is an infectious disease caused by Fasciola parasites, which are flat worms referred to as liver flukes. The adult (mature) flukes are found in the bile ducts and liver of infected people and animals, such as sheep and cattle. In general, fascioliasis is more common in livestock and other animals than in people.\n",
      "PREDICTION:\n",
      " \n",
      "    These resources address the diagnosis or management of Parasites:  - Genetic Testing Registry: Parasites  - MedlinePlus Encyclopedia: Parasite  - MedlinePlus Encyclopedi\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Parasites - Fusarium (Fusarium Infection)?\n",
      "    ### Response:\n",
      "    These resources address the diagnosis or management of Parasites:  - Genetic Testing Registry: Parasites  - MedlinePlus Encyclopedia: Parasite  - MedlinePlus Encyclopedi\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Parasites - Fusarium (Fusarium Infection)?\n",
      "ICL prompt complete\n",
      "184 142\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "160 160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "161 144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 153\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 143\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 165\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 149\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 141\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "149 144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 140\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "169 155\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "173 133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 146\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 140\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 160\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "157 137\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "191 133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "175 152\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "202 138\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "160 204\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "159 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "150 146\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 166\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "169 172\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 184\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "164 199\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "183 133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 144\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 149\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 163\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "188 164\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "179 162\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 143\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 143\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 166\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 142\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "164 174\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "158 146\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 139\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "146 153\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "154 155\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 151\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "172 203\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "163 143\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "178 141\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "179 170\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "DOING BLEURT\n",
      "DONE BLEURT\n",
      "ICL prompt complete\n",
      "152 255\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is Fatal familial insomnia inherited ?\n",
      "    ### Response:\n",
      "    How is fatal familial insomnia inherited? Fatal familial insomnia (FFI) is inherited in an autosomal dominant manner. This means that to be affected, a person only needs a change (mutation) in one copy of the responsible gene in each cell. In some cases, an affected person inherits the mutation from an affected parent.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is Protein C deficiency inherited ?\n",
      "    ### Response:\n",
      "    How is protein C deficiency inherited? Hereditary protein C deficiency is inherited in an autosomal dominant manner. This means that having only one mutated copy of the responsible gene in each cell is enough to cause mild protein C deficiency. A mutated copy of the gene can be inherited from a person's mother or father.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is anencephaly inherited ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Most cases of anencephaly are sporadic, which means they occur in people with no history of the disorder in their family. A small percentage of cases have been reported to run in families; however, the condition does not have a clear pattern of inheritance.\n",
      "PREDICTION:\n",
      " \n",
      "    How is anencephaly inherited? Anencephaly is inherited in an autosomal dominant manner. This means that the affected person inherits the mutation from an affected parent.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.    ### Instruction:\n",
      "    Is anencephaly inherited by a person?\n",
      "    ### Response:\n",
      "    How is anencephaly inherited by a person? Anencephaly is inherited in an autosomal dominant manner. This means that the affected person inherits the mutation from an affected parent.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.    ### Instruction:\n",
      " \n",
      "ICL prompt complete\n",
      "158 259\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 265\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 270\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "182 253\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "190 231\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "155 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 256\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "172 282\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "155 259\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "158 237\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "161 259\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 253\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "159 261\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "169 247\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "151 256\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 297\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 233\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 251\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 275\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 244\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 294\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "187 252\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 295\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 245\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 265\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "173 257\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 248\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 275\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 280\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 266\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 237\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "160 249\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "158 256\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "153 255\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 277\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 266\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "151 255\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "148 283\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "153 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "156 305\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 256\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "185 244\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "161 297\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 246\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 252\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "164 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "175 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 270\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 257\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What are the treatments for protein S deficiency ?\n",
      "    ### Response:\n",
      "    These resources address the diagnosis or management of protein S deficiency:  - Genetic Testing Registry: Protein S deficiency  - MedlinePlus Encyclopedia: Congenital Protein C or S Deficiency  - MedlinePlus Encyclopedia: Necrosis  - MedlinePlus Encyclopedi\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What are the treatments for juvenile primary osteoporosis ?\n",
      "    ### Response:\n",
      "    These resources address the diagnosis or management of juvenile primary osteoporosis:  - Lucile Packard Children's Hospital at Stanford: Juvenile Osteoporosis  - MedlinePlus Encyclopedia: Bone Mineral Density Test  - Merck Manual Home Health Edition: Osteop\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Parasites - Fascioliasis (Fasciola Infection) ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Fascioliasis is an infectious disease caused by Fasciola parasites, which are flat worms referred to as liver flukes. The adult (mature) flukes are found in the bile ducts and liver of infected people and animals, such as sheep and cattle. In general, fascioliasis is more common in livestock and other animals than in people.\n",
      "PREDICTION:\n",
      " \n",
      "    These resources address the diagnosis or management of Parasites - Fascioliasis (Fasciola Infection) - MedlinePlus Encyclopedia: Bone Mineral Density Test  - Merck Manual Home Health Edition: Osteop\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What are the treatments for (non-malignant) cancer?\n",
      "    ### Response:\n",
      "    These resources address the diagnosis or management of (non-malignant) cancer:  - Cancer Center of Excellence: Cancer Center of Excellence  - Merck Manual Home Health Edition: Osteop\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What are the treatments for (non-mal\n",
      "ICL prompt complete\n",
      "184 247\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "160 266\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "161 264\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "171 251\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 273\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 254\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 290\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "149 243\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 254\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "169 254\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "173 244\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 245\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 248\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 257\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "157 245\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "191 296\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "175 260\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "202 253\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 256\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "160 312\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "159 244\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "150 251\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 275\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "169 280\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 297\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "164 304\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "183 236\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 243\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 259\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 253\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 283\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "188 284\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "179 282\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 257\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 251\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 295\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 257\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "164 295\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "158 270\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 260\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "146 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "154 270\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 266\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 248\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "172 311\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "163 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "178 233\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "179 269\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "DOING BLEURT\n",
      "DONE BLEURT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_num_egs = 3\n",
    "\n",
    "data = load_dataset('Laurent1/MedQuad-MedicalQnADataset_128tokens_max')['train']\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "tokenizer = tokenizer_gpt2\n",
    "model = model_gpt2\n",
    "\n",
    "def filter_example(example):\n",
    "    return count_tokens(tokenizer, extract_response_content(example['text'], \"### Response:\")) <= 300\n",
    "\n",
    "data = data.filter(filter_example)\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test'].select(range(100))\n",
    "\n",
    "\n",
    "max_token_dict = {}\n",
    "for example in test_dataset:\n",
    "    real = extract_response_content(example['text'], \"### Response:\")\n",
    "    max_token_dict[real] = count_tokens(tokenizer, real)\n",
    "\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name='medqa')\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "# avg_tokens = 0\n",
    "# for eg in train_list:\n",
    "#     avg_tokens+= count_tokens(tokenizer_mist, eg)\n",
    "# avg_tokens  = avg_tokens/len(train_list)\n",
    "# print(\"AVG TOKENS: \",avg_tokens)\n",
    "#avg_tokens = \n",
    "\n",
    "\n",
    "icl_method = 'similarity'\n",
    "model_name = 'gpt2_small'\n",
    "ds_name = 'medqa'\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "\n",
    "\n",
    "for i in range(max_num_egs):\n",
    "    accuracy = 0\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model, tokenizer, i, model_name=model_name, ds_name=ds_name, method=icl_method, max_tokens_dict=max_token_dict)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    print(\"order: \", order)\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order=order)\n",
    "    print(\"DOING BLEURT\")\n",
    "    bleurt_score = bleurt.compute(predictions=preds, references=reals)\n",
    "    print(\"DONE BLEURT\")\n",
    "    avg_bleurt = sum(bleurt_score['scores'])/len(bleurt_score['scores'])\n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations' : i, 'bert_score' : float(average_F1), 'bleu_score' : bleu_score['bleu'], 'bleurt' : avg_bleurt})\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/{icl_method}/icl_results_{ds_name}_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Law QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set:  100\n",
      "Length of train set 1579\n",
      "ICL prompt complete\n",
      "261 113\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: My son was jumped by 6 students and the school has done nothing. I want to sue for failure to provide a safe environment. The school has know about the situation for three weeks but have done nothing. They don’t believe my child was jumped but has also failed to provide the surveillance footage of the attack. They told me one child came forward and said he hit my child too hard. The school expects my child to continue his education in an environment where he doesn’t feel safe or protected. \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:As a parent, it's distressing to hear that your child's safety is at risk. If the school is not addressing your concerns adequately, you might consider taking legal action. Schools have a duty to provide a safe environment for students. You can request the surveillance footage formally through a written request; if the school refuses, this may be something that can be compelled through legal means. Document all interactions with the school regarding this issue. It would be prudent to consult with an attorney who handles education law to explore the possibility of a lawsuit for failing to provide a safe environment for your child. They can guide you on how to proceed with obtaining evidence and how to protect your son's rights. Ensure that your son's experiences are also recorded, as his account may be crucial for any legal action.\n",
      "PREDICTION:\n",
      "  I am a parent of a child who was attacked by 6 students and the school has not provided a safe environment for him. I want to sue for failure to provide a safe environment. The school has know about the situation for three weeks but have done nothing. They don’t believe my child was jumped but has also failed to provide the surveillance footage of the attack. They told me one child came forward and said he hit my child too hard. The school expects my child to continue his education in an environment where he doesn’t feel safe or protected. \n",
      "\n",
      "### Question: My son was jumped by 6 students and the school has done nothing. I want to sue for failure to provide a safe environment. The school has know about the situation for three weeks but have done nothing. They don’t believe my child was jumped but has also failed to provide the surveillance footage of the attack. They told me one child came forward and said he hit my child too hard. The school expects my child to continue his education in an environment where he doesn’t feel safe or protected. \n",
      "\n",
      "### Question: My son was jumped by 6 students and the school has done nothing. I want to sue for failure to provide a safe environment. The school has know about the\n",
      "ICL prompt complete\n",
      "154 67\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "256 50\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "116 238\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "141 61\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "173 90\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "194 79\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "229 105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "113 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "168 117\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "282 67\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "258 53\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "214 87\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "211 48\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 66\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "189 145\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "352 43\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "312 71\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 61\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 83\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 64\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "132 84\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "113 110\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "233 120\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "200 174\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "206 95\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "256 53\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "142 91\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "312 60\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "325 33\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 87\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 117\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "225 64\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "276 72\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 53\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "157 52\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 222\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "128 251\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "269 77\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "149 78\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "155 135\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "202 136\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "345 43\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "189 88\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "241 65\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 174\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "203 114\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "228 52\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "211 55\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "201 63\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "315 61\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: How do I stop my husband from spending his children's money?. My husband gets SSDI and our children gets money from his disability. Is there a way to keep him from spending their money since he is on the account he set up for them? \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:Certainly. If the money your children receive is from SSDI, it's intended for their care and support. If you believe your husband is misusing these funds, there are steps you can consider: 1. Document the misuse: Gather evidence showing the inappropriate spending or diversion of funds. 2. Apply to be the representative payee: The Social Security Administration (SSA) allows for another individual, usually a parent, to be designated as the representative payee to handle the funds for the child's benefit. 3. Once appointed, set up a dedicated account for these funds, ensuring that only authorized expenses related to the child's well-being are paid from this account. 4. If the situation escalates, you may need to consult with legal counsel for potential family court intervention, especially if the children's welfare is at risk. 5. Always communicate your concerns with the SSA; they have a vested interest in ensuring benefits are used appropriately. 6. Lastly, prioritize your children's best interests and consider seeking mediation or counseling to address underlying financial disputes.\n",
      "PREDICTION:\n",
      "  I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a question about SSDI. I have a\n",
      "ICL prompt complete\n",
      "174 61\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "143 138\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "313 66\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 104\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "141 94\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "138 89\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "338 50\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "268 105\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "233 158\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "304 64\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "313 61\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "259 121\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 78\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 132\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "256 136\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "268 58\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 71\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "172 72\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "200 53\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "146 133\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "312 64\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "183 66\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "320 56\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "153 187\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "203 117\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "267 97\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 102\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "136 244\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "340 42\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "146 46\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "131 66\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "202 108\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "258 130\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "163 59\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "184 80\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 226\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 77\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "252 128\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "275 57\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "327 61\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "142 80\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 39\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "116 121\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 46\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "159 202\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "210 164\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "254 125\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "258 51\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "335 52\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOING BLEURT\n",
      "DONE BLEURT\n",
      "ICL prompt complete\n",
      "261 290\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: if a child is at school and throws a rock and it hits a vehicle who is responsible the parent or the school?. a child threw a rock and it accidentally stuck a vehicle during school under school supervision who is responsible for the cost of the damages? \n",
      " ### Answer: A:if a child throws a rock and it hits a vehicle while the child is at school and under school supervision, the school district is typically responsible for the cost of the damages. This is because the school district has a duty to supervise its students and to take reasonable steps to prevent them from harming others. However, there are some exceptions to this rule. For example, if the child's actions were intentional or malicious, the school district may not be liable for the damages. Additionally, if the child's parents have homeowners insurance, their policy may cover the damages.\n",
      "### Question: Q: My son was jumped by 6 students and the school has done nothing. I want to sue for failure to provide a safe environment. The school has know about the situation for three weeks but have done nothing. They don’t believe my child was jumped but has also failed to provide the surveillance footage of the attack. They told me one child came forward and said he hit my child too hard. The school expects my child to continue his education in an environment where he doesn’t feel safe or protected. \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:As a parent, it's distressing to hear that your child's safety is at risk. If the school is not addressing your concerns adequately, you might consider taking legal action. Schools have a duty to provide a safe environment for students. You can request the surveillance footage formally through a written request; if the school refuses, this may be something that can be compelled through legal means. Document all interactions with the school regarding this issue. It would be prudent to consult with an attorney who handles education law to explore the possibility of a lawsuit for failing to provide a safe environment for your child. They can guide you on how to proceed with obtaining evidence and how to protect your son's rights. Ensure that your son's experiences are also recorded, as his account may be crucial for any legal action.\n",
      "PREDICTION:\n",
      "  A: If the school has a duty to protect its students, it must provide a safe environment for their students. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements. The school must provide a safe environment for its students to be safe from the elements.\n",
      "ICL prompt complete\n",
      "154 209\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "256 211\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "116 521\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "141 238\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "173 284\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "194 212\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "229 280\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "113 205\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "168 287\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "282 324\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "258 304\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "214 343\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "211 321\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 324\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "189 384\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "352 319\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "312 270\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 255\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 356\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 157\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "132 328\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "113 396\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "233 408\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "200 457\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "206 337\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "256 155\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "142 204\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "312 311\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "325 204\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 215\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 373\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "225 112\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "276 372\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 339\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "157 224\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 503\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "128 526\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "269 305\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "149 198\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "155 315\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "202 242\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "345 217\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "189 358\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "241 341\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 474\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "203 313\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "228 224\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "211 229\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "201 202\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "315 195\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: Is there a legal way to be exempt from paying tax? Also a legal way to cash out all of your social security?. I want to be able to have money for my retirement or to leave to my children when I pass away with the New president election for 2020 im afraid I will loss all the money put into my social security over the years and im not willing to risk that because are new president wants to change are constitutional right as usa citizens this is a real concern of mine and my right as a taxpayer \n",
      " ### Answer: A:Although you cannot avoid taxes, you may want to look into trusts in South Dakota.\n",
      "### Question: Q: How do I stop my husband from spending his children's money?. My husband gets SSDI and our children gets money from his disability. Is there a way to keep him from spending their money since he is on the account he set up for them? \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:Certainly. If the money your children receive is from SSDI, it's intended for their care and support. If you believe your husband is misusing these funds, there are steps you can consider: 1. Document the misuse: Gather evidence showing the inappropriate spending or diversion of funds. 2. Apply to be the representative payee: The Social Security Administration (SSA) allows for another individual, usually a parent, to be designated as the representative payee to handle the funds for the child's benefit. 3. Once appointed, set up a dedicated account for these funds, ensuring that only authorized expenses related to the child's well-being are paid from this account. 4. If the situation escalates, you may need to consult with legal counsel for potential family court intervention, especially if the children's welfare is at risk. 5. Always communicate your concerns with the SSA; they have a vested interest in ensuring benefits are used appropriately. 6. Lastly, prioritize your children's best interests and consider seeking mediation or counseling to address underlying financial disputes.\n",
      "PREDICTION:\n",
      "  A: There is a way to keep your children from spending their money.\n",
      "### Question: Q: How do I stop my husband from spending his children's money?. My husband gets SSDI and our children gets money from his disability. Is there a way to keep him from spending their money since he is on the account he set up for them? \n",
      "### Question: Q: How do I stop my husband from spending his children's money?. My husband gets SSDI and our children gets money from his disability. Is there a way to keep him from spending their money since he is on the account he set up for them? \n",
      "### Question: Q: How do I stop my husband from spending his children's money?. My husband gets SSDI and our children gets money from his disability. Is there a way to keep him from spending their money since he is on the account he set up for them? \n",
      "### Question: Q: How do I stop my husband from spending his children's money?. My husband gets SSDI and our children gets money from his disability. Is there a way to keep him from spending their money since he is on the account he set up for them? \n",
      "### Question: Q: How do I stop my husband from spending his children's money?. My husband gets SSDI and our children gets money from his disability. Is there a way to keep him from spending their money since he is on the account he set up for them? \n",
      "### Question: Q: How do I stop\n",
      "ICL prompt complete\n",
      "174 206\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "143 363\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "313 339\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 387\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "141 293\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "138 264\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "338 336\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "268 308\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "233 352\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "304 240\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "313 202\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "259 338\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 198\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 238\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "256 238\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "268 309\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 349\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "172 252\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "200 291\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "146 327\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "312 227\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "183 275\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "320 331\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "153 367\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "203 258\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "267 146\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 356\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "136 448\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "340 320\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "146 180\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "131 149\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "202 219\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "258 324\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "163 165\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "184 222\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 452\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 271\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "252 379\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "275 182\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "327 344\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "142 255\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 149\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "116 407\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 242\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "159 400\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "210 273\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "254 266\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "258 99\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "335 276\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOING BLEURT\n",
      "DONE BLEURT\n",
      "ICL prompt complete\n",
      "261 513\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: if a child is at school and throws a rock and it hits a vehicle who is responsible the parent or the school?. a child threw a rock and it accidentally stuck a vehicle during school under school supervision who is responsible for the cost of the damages? \n",
      " ### Answer: A:if a child throws a rock and it hits a vehicle while the child is at school and under school supervision, the school district is typically responsible for the cost of the damages. This is because the school district has a duty to supervise its students and to take reasonable steps to prevent them from harming others. However, there are some exceptions to this rule. For example, if the child's actions were intentional or malicious, the school district may not be liable for the damages. Additionally, if the child's parents have homeowners insurance, their policy may cover the damages.\n",
      "### Question: Q: Can I sue for emotional distress caused by an animal rescue adopting a dog out from under me?. We were strung along for days after being approved for adoption. 45min before we were supposed to get the dog I was as informed via text that he went to a foster and they’d have to see when they’d be available. Fast forward to the next day, I’ve still heard no word. So I reach out only to be told those people had decided to adopt him. My three children are devastated, we bought items for the new family member. \n",
      " ### Answer: A:Like in most jurisdictions, South Carolina law considers dogs to be items of personal property like a TV set or a lamp. The value of a dog for purposes of legal damages is the fair market value of the dog at the time of the loss. As in most jurisdictions, SC law does not allow any recovery for emotional distress caused by the loss of personal property. Much as some like to consider their pets \"family members,\" the law in most places does not.\n",
      "### Question: Q: My son was jumped by 6 students and the school has done nothing. I want to sue for failure to provide a safe environment. The school has know about the situation for three weeks but have done nothing. They don’t believe my child was jumped but has also failed to provide the surveillance footage of the attack. They told me one child came forward and said he hit my child too hard. The school expects my child to continue his education in an environment where he doesn’t feel safe or protected. \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:As a parent, it's distressing to hear that your child's safety is at risk. If the school is not addressing your concerns adequately, you might consider taking legal action. Schools have a duty to provide a safe environment for students. You can request the surveillance footage formally through a written request; if the school refuses, this may be something that can be compelled through legal means. Document all interactions with the school regarding this issue. It would be prudent to consult with an attorney who handles education law to explore the possibility of a lawsuit for failing to provide a safe environment for your child. They can guide you on how to proceed with obtaining evidence and how to protect your son's rights. Ensure that your son's experiences are also recorded, as his account may be crucial for any legal action.\n",
      "PREDICTION:\n",
      "  A:The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any information about the incident. The school has not provided any\n",
      "ICL prompt complete\n",
      "154 432\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "256 415\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "116 695\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "141 368\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "173 578\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "194 513\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "229 410\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "113 478\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "168 369\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "282 526\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "258 585\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "214 626\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "211 538\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 567\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "189 576\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "352 471\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "312 473\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "176 470\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "165 563\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 298\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "132 533\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "113 672\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "233 697\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "200 682\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "206 575\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "256 330\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "142 446\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "312 415\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "325 499\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "162 432\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 666\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "225 242\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "276 643\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 630\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "157 337\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "167 586\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "128 820\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "269 447\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "149 293\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "155 509\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "202 390\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "345 492\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "189 550\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "241 564\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "181 605\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "203 459\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "228 337\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "211 329\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "201 365\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "315 397\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: Is there a legal way to be exempt from paying tax? Also a legal way to cash out all of your social security?. I want to be able to have money for my retirement or to leave to my children when I pass away with the New president election for 2020 im afraid I will loss all the money put into my social security over the years and im not willing to risk that because are new president wants to change are constitutional right as usa citizens this is a real concern of mine and my right as a taxpayer \n",
      " ### Answer: A:Although you cannot avoid taxes, you may want to look into trusts in South Dakota.\n",
      "### Question: Q: I been married for 19yrs and have been a Military stay at home mom and my husband is decided he doesn’t want me anymore. He has been in the military for for almost 19yrs and I have been by his side all these years and he says he only has to pay child support and I get nothing from him. I need help! \n",
      " ### Answer: A:You are absolutely entitled to more than just child support. Your military spouse is likely going to receive a military pension, which is a considered to visible property, and you will be entitled to a portion of that property in the divorce process as you would any other piece of property such as a house or investment fund. I highly recommend that you retain an attorney who specializes in military benefits for the resolution of your divorce case. In the meantime, I would recommend that you contact his chain of command, and request that he be ordered to provide interim support to you during the ongoing divorce process and separation.\n",
      "### Question: Q: How do I stop my husband from spending his children's money?. My husband gets SSDI and our children gets money from his disability. Is there a way to keep him from spending their money since he is on the account he set up for them? \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:Certainly. If the money your children receive is from SSDI, it's intended for their care and support. If you believe your husband is misusing these funds, there are steps you can consider: 1. Document the misuse: Gather evidence showing the inappropriate spending or diversion of funds. 2. Apply to be the representative payee: The Social Security Administration (SSA) allows for another individual, usually a parent, to be designated as the representative payee to handle the funds for the child's benefit. 3. Once appointed, set up a dedicated account for these funds, ensuring that only authorized expenses related to the child's well-being are paid from this account. 4. If the situation escalates, you may need to consult with legal counsel for potential family court intervention, especially if the children's welfare is at risk. 5. Always communicate your concerns with the SSA; they have a vested interest in ensuring benefits are used appropriately. 6. Lastly, prioritize your children's best interests and consider seeking mediation or counseling to address underlying financial disputes.\n",
      "PREDICTION:\n",
      "  A:There is a way to keep your husband from spending his children's money. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his children's money:1. You can use the following steps to keep your husband from spending his\n",
      "ICL prompt complete\n",
      "174 405\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "143 646\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "313 533\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "118 528\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "141 516\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "138 441\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "338 446\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "268 531\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "233 458\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "304 388\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "313 295\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "259 561\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 469\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "120 432\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "256 377\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "268 429\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "177 432\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "172 358\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "200 483\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "146 550\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "312 403\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "183 527\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "320 473\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "153 570\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "203 432\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "267 288\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "180 553\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "136 576\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "340 531\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "146 262\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "131 297\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "202 302\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "258 504\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "163 213\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "184 480\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "152 676\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "170 375\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "252 622\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "275 278\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "327 639\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "142 480\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "174 234\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "116 601\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "166 493\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "159 623\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "210 453\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "254 405\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "258 229\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "335 549\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOING BLEURT\n",
      "DONE BLEURT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_num_egs = 3\n",
    "\n",
    "data = load_dataset('dzunggg/legal-qa-v1')['train']\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "tokenizer = tokenizer_gpt2\n",
    "model = model_gpt2\n",
    "\n",
    "def filter_example(example):\n",
    "    return count_tokens(tokenizer, f\"### Question: {example['question']}\\n ### Answer: {example['answer']}\") <= 300\n",
    "\n",
    "data = data.filter(filter_example)\n",
    "\n",
    "train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test'].select(range(100))\n",
    "\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name='lawqa')\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "max_token_dict = {}\n",
    "for eg in test_dataset:\n",
    "    max_token_dict[eg['answer']] = count_tokens(tokenizer, eg['answer'])\n",
    "\n",
    "# avg_tokens = 0\n",
    "# for eg in train_list:\n",
    "#     avg_tokens+= count_tokens(tokenizer_mist, eg)\n",
    "# avg_tokens  = avg_tokens/len(train_list)\n",
    "# print(\"AVG TOKENS: \",avg_tokens)\n",
    "#avg_tokens = \n",
    "\n",
    "\n",
    "\n",
    "# print(\"Token Dict complete\")\n",
    "\n",
    "icl_method = 'similarity'\n",
    "model_name = 'gpt2_small'\n",
    "ds_name = 'lawqa'\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "\n",
    "\n",
    "for i in range(max_num_egs):\n",
    "    accuracy = 0\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model, tokenizer, i, model_name=model_name, ds_name=ds_name, method=icl_method, max_tokens_dict=max_token_dict)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order=order)\n",
    "    print(\"DOING BLEURT\")\n",
    "    bleurt_score = bleurt.compute(predictions=preds, references=reals)\n",
    "    print(\"DONE BLEURT\")\n",
    "    avg_bleurt = sum(bleurt_score['scores'])/len(bleurt_score['scores'])\n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations' : i, 'bert_score' : float(average_F1), 'bleu_score' : bleu_score['bleu'], 'bleurt':avg_bleurt})\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/{icl_method}/icl_results_{ds_name}_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging ICL Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    bert_score  bleu_score    bleurt\n",
      "num_demonstrations                                  \n",
      "0                     0.670628    0.087276 -1.232413\n",
      "1                     0.834500    0.129618 -1.137657\n",
      "2                     0.833667    0.131596 -1.056782\n",
      "3                     0.861578    0.124963 -1.378967\n",
      "4                     0.840916    0.051867 -1.773363\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing your CSV files\n",
    "directory = 'icl_results/random'\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv') and 'gpt2_small' in filename:\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "grouped_df = concatenated_df.groupby('num_demonstrations')[['bert_score', 'bleu_score', 'bleurt']].mean()\n",
    "print(grouped_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    bert_score  bleu_score    bleurt\n",
      "num_demonstrations                                  \n",
      "0                     0.670628    0.087276 -0.924396\n",
      "1                     0.833230    0.139398 -0.577644\n",
      "2                     0.837789    0.136516 -0.537595\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing your CSV files\n",
    "directory = 'icl_results/similarity'\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv') and 'gpt2_small' in filename:\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "grouped_df = concatenated_df.groupby('num_demonstrations')[['bert_score', 'bleu_score', 'bleurt']].mean()\n",
    "print(grouped_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    bert_score  bleu_score    bleurt\n",
      "num_demonstrations                                  \n",
      "0                     0.827385    0.124019 -1.116392\n",
      "1                     0.847577    0.153620 -1.065689\n",
      "2                     0.850429    0.149902 -1.055004\n",
      "3                     0.861899    0.116885 -1.338390\n",
      "4                     0.861151    0.112602 -1.381159\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing your CSV files\n",
    "directory = 'icl_results/random'\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv') and 'mistral' in filename:\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "grouped_df = concatenated_df.groupby('num_demonstrations')[['bert_score', 'bleu_score', 'bleurt']].mean()\n",
    "print(grouped_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    bert_score  bleu_score    bleurt\n",
      "num_demonstrations                                  \n",
      "0                     0.825989    0.121709 -0.751007\n",
      "1                     0.848177    0.154961 -0.636657\n",
      "2                     0.854141    0.159165 -0.573506\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing your CSV files\n",
    "directory = 'icl_results/similarity'\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv') and 'mistral' in filename:\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dfs.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "grouped_df = concatenated_df.groupby('num_demonstrations')[['bert_score', 'bleu_score', 'bleurt']].mean()\n",
    "print(grouped_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
