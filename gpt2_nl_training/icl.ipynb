{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICL - GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "c:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk, load_metric\n",
    "import json\n",
    "import bert_score\n",
    "import evaluate\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk, load_metric\n",
    "import bert_score\n",
    "import evaluate\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device being used:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "sent_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def sent_similarity(sent1, sent2):\n",
    "    sentences = [sent1, sent2]\n",
    "    embeddings = sent_model.encode(sentences)\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    return similarity_matrix[0][1]\n",
    "\n",
    "\n",
    "def format_examples(ds, ds_name='ni'):\n",
    "    prompts = []\n",
    "    if ds_name == 'ni':\n",
    "        for example in ds:\n",
    "            # prompt = f\"### Question: {example['input']} \\n ###Targets: {example['output']}\"\n",
    "            prompt = f\"### Task: {example['definition']}\\n ### Inputs: {example['inputs']}\\n ### Targets: {example['targets']}\"\n",
    "            prompts.append(prompt)\n",
    "    elif ds_name == 'medmcq':\n",
    "         for example in ds:\n",
    "            prompt = f\"### Task: {example['instruction']}\\n ### Question: {example['input']}\\n ### Targets: {example['output']}\"\n",
    "            prompts.append(prompt)\n",
    "    elif ds_name == 'finance_sent':\n",
    "        for example in ds:\n",
    "            prompt = f\"### Text: {example['text']}\\n ### Targets: {example['label']}\"\n",
    "            prompts.append(prompt)\n",
    "    elif ds_name == 'medqa':\n",
    "        for example in ds:\n",
    "            prompts.append(example['text'])\n",
    "    elif ds_name == 'lawqa':\n",
    "        for example in ds:\n",
    "            prompt = f\"### Question: {example['question']}\\n ### Answer: {example['answer']}\"\n",
    "            prompts.append(prompt)\n",
    "\n",
    "    return prompts\n",
    "\n",
    "def select_characters_before_target(string, target_phrase=\"\\n ### Targets:\"): #this is a function to remove the actual target values from the train example so that the matching can be improved\n",
    "    target_index = string.find(target_phrase)\n",
    "    if target_index != -1:  # If the phrase is found\n",
    "        return string[:target_index] + target_phrase\n",
    "    else:\n",
    "        return string \n",
    "    \n",
    "def extract_response_content(string, target_phrase):\n",
    "    response_index = string.find(target_phrase)\n",
    "    return string[response_index + len(target_phrase):].strip()\n",
    "\n",
    "def group_examples_random(ds, n): #this is where we group examples into a larger prompt\n",
    "    random.seed()\n",
    "    samples = random.sample(ds, n)\n",
    "    new_prompt = \"\"\n",
    "    for i in range(n):\n",
    "        new_prompt += samples[i]\n",
    "        new_prompt += \"\\n\"\n",
    "    return new_prompt\n",
    "\n",
    "def group_by_similarity(prompt, ds, n_egs, m_choices, target_phrase=\"\\n ### Targets:\"):\n",
    "    choices = random.sample(ds, m_choices)\n",
    "    cos_sim_dict = {}\n",
    "    for c in choices:\n",
    "        cos_sim_dict[c] = sent_similarity(prompt, select_characters_before_target(c, target_phrase))\n",
    "\n",
    "    sorted_cos_sim = sorted(cos_sim_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_egs = \"\"\n",
    "    for item in sorted_cos_sim[:n_egs]:\n",
    "        top_egs += item[0]\n",
    "        top_egs += \"\\n\"\n",
    "\n",
    "    # top_egs = \"\".join([item[0] for item in sorted_cos_sim[:n_egs]])\n",
    "    return top_egs\n",
    "\n",
    "def count_tokens(tokenizer, prompt):\n",
    "    input_ids = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "    return len(input_ids)\n",
    "\n",
    "\n",
    "def evaluate_example(model, tokenizer, prompt, model_name, max_tokens):\n",
    "    if model_name == 'gpt2':\n",
    "        tokenized_prompt = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "        if len(tokenized_prompt['input_ids'][0]) > MAX_LENGTH: #currently just checking if random prompt is too big or not\n",
    "            return None \n",
    "        outputs =model.generate(**tokenized_prompt, pad_token_id=tokenizer.eos_token_id, max_length=1024)\n",
    "        decoded_output = tokenizer.decode(outputs[0][len(tokenized_prompt['input_ids'][0]):], skip_special_tokens=True)\n",
    "        return decoded_output\n",
    "    elif model_name == 'mistral':\n",
    "        # num_tokens = count_tokens(tokenizer, prompt)\n",
    "        # print(num_tokens)\n",
    "        # if num_tokens > 3400:\n",
    "        #     return None\n",
    "        model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        outputs =model.generate(**model_inputs, pad_token_id=tokenizer.eos_token_id, do_sample=True, max_new_tokens=max_tokens)\n",
    "        decoded_output = tokenizer.decode(outputs[0][len(model_inputs['input_ids'][0]):], skip_special_tokens=True) #only get output\n",
    "        return decoded_output\n",
    "  \n",
    "\n",
    "def evaluate_icl(train_dataset, test_dataset, model, tokenizer, num_egs, model_name, ds_name='ni', method='similarity', max_tokens_dict=None):\n",
    "    reals = []\n",
    "    preds = []\n",
    "    counter = 0\n",
    "    for example in test_dataset:\n",
    "        # prompt = group_examples(train_dataset, num_egs) + f\"### Question: {example['input']} \\n ###Targets:\"\n",
    "        target_phrase = \"\\n ### Targets:\"\n",
    "        if ds_name == 'ni':\n",
    "            curr_prompt = f\"### Task: {example['definition']}\\n ### Inputs: {example['inputs']}\\n ### Targets:\"\n",
    "            real = f\"{example['targets']}\"\n",
    "        elif ds_name == 'medmcq':\n",
    "            curr_prompt = f\"### Task: {example['instruction']}\\n ### Question: {example['input']}\\n ### Targets:\"\n",
    "            real = f\"{example['output']}\"\n",
    "            tokens = tokenizer(real, return_tensors='pt').to(device)\n",
    "            max_tokens = len(tokens['input_ids'][0])\n",
    "        elif ds_name == 'finance_sent':\n",
    "            curr_prompt = f\"### Text: {example['text']}\\n ### Targets:\"\n",
    "            real = f\"{example['label']}\"\n",
    "            tokens = tokenizer(real, return_tensors='pt').to(device)\n",
    "            max_tokens = len(tokens['input_ids'][0])\n",
    "        elif ds_name == 'medqa':\n",
    "            curr_prompt = select_characters_before_target(example['text'], \"### Response:\")\n",
    "            real = extract_response_content(example['text'], \"### Response:\")\n",
    "            max_tokens = max_tokens_dict[real] + 100\n",
    "        elif ds_name == 'lawqa':\n",
    "            curr_prompt = f\"### Question: {example['question']}\\n ### Answer:\"\n",
    "            real = example['answer']\n",
    "            max_tokens = max_tokens_dict[real] + 100\n",
    "            target_phrase = \"### Answer:\"\n",
    "\n",
    "        # tokens = tokenizer(real, return_tensors='pt').to(device)\n",
    "        # max_tokens = len(tokens['input_ids'][0])\n",
    "    \n",
    "        if method == 'similarity':\n",
    "            icl_prompt = group_by_similarity(curr_prompt,train_dataset, num_egs, 100, target_phrase) + curr_prompt\n",
    "        elif method == 'random':\n",
    "            icl_prompt = group_examples_random(train_dataset, num_egs) + curr_prompt\n",
    "\n",
    "        # print(\"MAX TOKENS:\\n\", max_tokens)\n",
    "        # print(\"\\n ICL Prompt: \",icl_prompt)\n",
    "        print(\"ICL prompt complete\")\n",
    "        pred = evaluate_example(model, tokenizer, icl_prompt, model_name, max_tokens)\n",
    "        print(\"Prediction complete\")\n",
    "\n",
    "        if counter % 50 == 0:\n",
    "            print(\"PROMPT:\\n\", icl_prompt)\n",
    "            print(\"REAL ANSWER:\\n\", real)\n",
    "            print(\"PREDICTION:\\n\", pred)\n",
    "        if pred:\n",
    "            reals.append(real)\n",
    "            preds.append(pred)\n",
    "        counter+=1\n",
    "\n",
    "    return reals, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 21.50s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model_plain =  GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "# tokenizer_plain = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# print(\"models retrieved\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "load_in_4bit=True,\n",
    "bnb_4bit_use_double_quant=True,\n",
    "bnb_4bit_quant_type=\"nf4\",\n",
    "bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model_mist = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", quantization_config=bnb_config, device_map=\"auto\")\n",
    "tokenizer_mist = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "model_gpt2=  GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_example2(model, tokenizer, prompt):\n",
    "    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "    # print(prompt)\n",
    "    # if len(tokenized_prompt['input_ids'][0]) > MAX_LENGTH: #currently just checking if random prompt is too big or not\n",
    "    #     return None \n",
    "    outputs =model.generate(**model_inputs, pad_token_id= tokenizer.eos_token_id, do_sample=False, max_length = 10)\n",
    "    decoded_output = tokenizer.decode(outputs[0][len(model_inputs['input_ids'][0]):], skip_special_tokens=True)\n",
    "    # print(\"prediction: \",decoded_output)/\n",
    "    return decoded_output\n",
    "\n",
    "\n",
    "prompt = \"\"\" \"featuring an oscar-worthy performance => positive\\n\"\n",
    "    \"completely messed up => negative\\n\"\n",
    "    \"masterpiece => positive\\n\"\n",
    "    \"the action is stilted => negative\\n\"\n",
    "    \"by far the worst movie of the year =>\" \"\"\"\n",
    "pred = evaluate_example2(model_mist, tokenizer_mist, prompt) \n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Natural Instructions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_from_disk('data/1000_per_task')\n",
    "\n",
    "# data = filter_icl(data, max_num_egs, tokenizer_plain)\n",
    "\n",
    "max_num_egs =  5   #natural instructions are just too big\n",
    "\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "# train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "# train_dataset = train_test_split['train']\n",
    "# test_dataset = train_test_split['test']\n",
    "\n",
    "train_dataset = data['train']\n",
    "test_dataset = data['test'].select(range(5))\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset)\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "avg_tokens = 0\n",
    "for eg in train_list:\n",
    "    avg_tokens+= count_tokens(eg)\n",
    "avg_tokens  = avg_tokens/len(train_list)\n",
    "print(avg_tokens)\n",
    "\n",
    "icl_method = 'random'\n",
    "model_name = 'mistral'\n",
    "ds_name = 'ni'\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "for i in range(max_num_egs):\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model_mist, tokenizer_mist, i, model_name=model_name, ds_name=ds_name, method=icl_method)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    print(order)\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order= order) #set order to mean of real values\n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations':i, 'bert_score' : float(average_F1), 'bleu_score': bleu_score['bleu']})\n",
    "\n",
    "# results_df = pd.DataFrame(results_data)\n",
    "# results_df.to_csv(f'icl_results/icl_results_{ds_name}_{icl_method}_{model_name}.csv', index=False)\n",
    "\n",
    "# plt.figure(figsize=(10, 2))\n",
    "# plt.plot(range(max_num_egs), bert_scores) \n",
    "# plt.xlabel('Number of examples') \n",
    "# plt.ylabel('BERT F1 Score') \n",
    "# plt.title('BERT F1 Score vs Number of Examples') \n",
    "# plt.xticks(range(max_num_egs))\n",
    "# plt.savefig('BERT_scores_icl_ni.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(int(sum(len(s) for s in refs)/len(refs)))\n",
    "# test = bleu.compute(predictions=['No', 'Yes', 'Yes', 'yes', 'Yes', 'yes', 'yes', 'No', 'yes', 'No'],\n",
    "#                     references=['No.', 'Yes.', 'No.', 'Yes.', 'No.', 'Yes.', 'No.', 'Yes.', 'No.', 'Yes.'], max_order=int(sum(len(s) for s in refs)/len(refs)))\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Medical MCQ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set:  100\n",
      "Length of train set 8142\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Task: Please answer with one of the option in the bracket\n",
      " ### Question: Q:A 35-year-old woman comes to your office with a variety of complaints. As part of her evaluation, she undergoes laboratory testing which reveals the presence of anti-centromere antibodies. All of the following symptoms and signs would be expected to be present EXCEPT:? \n",
      "{'A': 'Pallor, cyanosis, and erythema of the hands', 'B': 'Calcium deposits on digits', 'C': 'Blanching vascular abnormalities', 'D': 'Hypercoagulable state', 'E': 'Heartburn and regurgitation'},\n",
      " ### Targets:\n",
      "REAL ANSWER:\n",
      " D: Hypercoagulable state\n",
      "PREDICTION:\n",
      " \n",
      "  -\n",
      "### Links:\n",
      "[\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_num_egs):\n\u001b[0;32m     24\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 25\u001b[0m     reals, preds \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_icl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_mist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43micl_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     P, R, F1 \u001b[38;5;241m=\u001b[39m bert_score\u001b[38;5;241m.\u001b[39mscore(preds, reals, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m     average_F1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(F1) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(F1)\n",
      "Cell \u001b[1;32mIn[44], line 139\u001b[0m, in \u001b[0;36mevaluate_icl\u001b[1;34m(train_dataset, test_dataset, model, tokenizer, num_egs, model_name, ds_name, method, max_tokens_dict)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# print(\"MAX TOKENS:\\n\", max_tokens)\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# print(\"\\n ICL Prompt: \",icl_prompt)\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mICL prompt complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 139\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micl_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[44], line 93\u001b[0m, in \u001b[0;36mevaluate_example\u001b[1;34m(model, tokenizer, prompt, model_name, max_tokens)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmistral\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# num_tokens = count_tokens(tokenizer, prompt)\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# print(num_tokens)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# if num_tokens > 3400:\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m#     return None\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m tokenizer([prompt], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 93\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     decoded_output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mlen\u001b[39m(model_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]):], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#only get output\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoded_output\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1652\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1644\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1645\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1646\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1647\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1648\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1649\u001b[0m     )\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[1;32m-> 1652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[0;32m   1667\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   1669\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1670\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1675\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   1676\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zakit\\Documents\\COMP0087 CW\\COMP0087-Group\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2770\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[38;5;66;03m# sample\u001b[39;00m\n\u001b[0;32m   2769\u001b[0m probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 2770\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   2772\u001b[0m \u001b[38;5;66;03m# finished sentences should have their next token be a padding token\u001b[39;00m\n\u001b[0;32m   2773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eos_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "max_num_egs = 5\n",
    "\n",
    "data = load_dataset('medalpaca/medical_meadow_medqa')['train']\n",
    "train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test'].select(range(100))\n",
    "\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name='medmcq')\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "icl_method = 'random'\n",
    "model_name = 'mistral'\n",
    "ds_name = 'medmcq'\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "\n",
    "\n",
    "for i in range(max_num_egs):\n",
    "    accuracy = 0\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model_mist, tokenizer_mist, i, model_name=model_name, ds_name=ds_name, method=icl_method)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    print(\"order: \", order)\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order=order)\n",
    "    for r,p in zip(reals, preds):\n",
    "        if len(p.strip()) != 0:\n",
    "            if r.strip()[0] == p.strip()[0]:\n",
    "                accuracy+=1\n",
    "    accuracy = accuracy/len(preds)\n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations' : i, 'bert_score' : float(average_F1), 'bleu_score' : bleu_score['bleu'], 'accuracy':accuracy})\n",
    "\n",
    "# results_df = pd.DataFrame(results_data)\n",
    "# results_df.to_csv(f'icl_results/icl_results_{ds_name}_{icl_method}_{model_name}.csv', index=False)\n",
    "\n",
    "# plt.figure(figsize=(10, 2))\n",
    "# plt.plot(range(max_num_egs), bert_scores) \n",
    "# plt.xlabel('Number of examples') \n",
    "# plt.ylabel('BERT F1 Score')\n",
    "# plt.title('BERT F1 Score vs Number of Examples') \n",
    "# plt.xticks(range(max_num_egs))\n",
    "# plt.savefig('BERT_scores_icl_medqa.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/icl_results_{ds_name}_{icl_method}_{model_name}.csv', index=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Transcript Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_num_egs = 5\n",
    "\n",
    "data = load_dataset('jlh-ibm/earnings_call', 'transcript-sentiment')['train']\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test'].select(range(100))\n",
    "\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name='finance_sent')\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "icl_method = 'similarity'\n",
    "model_name = 'mistral'\n",
    "ds_name = 'finance_sent'\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "\n",
    "\n",
    "for i in range(max_num_egs):\n",
    "    accuracy = 0\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model_mist, tokenizer_mist, i, model_name=model_name, ds_name=ds_name, method=icl_method)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    print(\"order: \", order)\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order=order)\n",
    "    for r,p in zip(reals, preds):\n",
    "        if len(p.strip()) != 0:\n",
    "            if r.strip()[0] == p.strip()[0]:\n",
    "                accuracy+=1\n",
    "    accuracy = accuracy/len(preds)\n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations' : i, 'bert_score' : float(average_F1), 'bleu_score' : bleu_score['bleu'], 'accuracy':accuracy})\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/icl_results_{ds_name}_{icl_method}_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Medicine QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15549\n",
      "Length of test set:  100\n",
      "Length of train set 12439\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is anencephaly inherited ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Most cases of anencephaly are sporadic, which means they occur in people with no history of the disorder in their family. A small percentage of cases have been reported to run in families; however, the condition does not have a clear pattern of inheritance.\n",
      "PREDICTION:\n",
      " \n",
      "    Anencephaly is not inherited. Anencephaly is a result of random, uncontrollable genetic mutations that occur after the fertilized egg begins to expand and divide into two cells , then four , then eight , and so on .\n",
      "    ### Instruction:\n",
      "    Is there a genetic component to anencephaly? Does a family history of anencephaly increase the risk of having a child born with anencephaly?\n",
      "    ### Response:\n",
      "    Anencephaly is considered to be a non-inheritable birth defect with a high recurrence rate . Therefore there is a great chance of it happening again . However a family history of anencephaly does not usually indicate the risk of a child being born with\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Parasites - Fascioliasis (Fasciola Infection) ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Fascioliasis is an infectious disease caused by Fasciola parasites, which are flat worms referred to as liver flukes. The adult (mature) flukes are found in the bile ducts and liver of infected people and animals, such as sheep and cattle. In general, fascioliasis is more common in livestock and other animals than in people.\n",
      "PREDICTION:\n",
      " \n",
      "    A parasite is a species that lives in or with a host organism or species. For its nutrition the parasite depends on that from the host or on the products of its metabolism. However, parasites do not produce their own food by themselves.\n",
      "    A parasite exists by either symbiosis or direct harm to the host. Many parasites harm the host, where they may reduce the efficiency of metabolism (eg by eating it from the inside).\n",
      "    Parasites come in many forms. Those that live within the cells of a multi-cellular host are called intracellular parasites (e.g., viruses, bacteria). One of the best known parasites is the plasmodium (the carrier of malaria). Other parasites live on the surface of the cell (e.g., certain viruses). These are called non-cell\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is Fryns syndrome inherited ?\n",
      "    ### Response:\n",
      "    How is Fryns syndrome inherited? Although the exact cause of Fryns syndrome is not currently known (and no disease-causing gene has yet been identified), it is thought to be genetic because it tends to \"run in families\" and has features common to other genetic disorders.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is anencephaly inherited ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Most cases of anencephaly are sporadic, which means they occur in people with no history of the disorder in their family. A small percentage of cases have been reported to run in families; however, the condition does not have a clear pattern of inheritance.\n",
      "PREDICTION:\n",
      " \n",
      "    Anencephaly is not inherited or genetic. Even though anencephaly has been linked to other genetic conditions (such as trisomy 18), most women who had a baby affected by anencephaly have babies who are not affected. Studies have shown, however, that some of the risk factors for anencephaly can be inherited\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Why is Bardet-Biedl syndrome considered a form of polydactyly?\n",
      "    ### Response:\n",
      "    \"Bardet-Biedl syndrome (BBS) is a genetic, autosomal, inherited disorder characterized by the combined presence of six abnormal\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Problems with Smell ?\n",
      "    ### Response:\n",
      "    You can help your doctor make a diagnosis by writing down important information about your problem beforehand and giving the information to your doctor during your visit. Write down answers to the following questions. - When did I first become aware of the \n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Parasites - Fascioliasis (Fasciola Infection) ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Fascioliasis is an infectious disease caused by Fasciola parasites, which are flat worms referred to as liver flukes. The adult (mature) flukes are found in the bile ducts and liver of infected people and animals, such as sheep and cattle. In general, fascioliasis is more common in livestock and other animals than in people.\n",
      "PREDICTION:\n",
      " \n",
      "    In the United States, the life cycle of the parasite Fasciola hepatica occurs in cattle and other domestic ruminants. Cattle serve as definitive hosts and are infected by larvae through grazing on pasture containing the larval-infested intermediate hosts (snails) or from drinking water contaminated by the larvae. Fasciola hepatica\n",
      "\n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Parasites - Parabasalids (Trichomonads) ?\n",
      "    ### Response:\n",
      "    Parabasalids are a large group of protozoa of variable size and shape, and are distributed widely in nature. They consist of seven genera, including Trichomonas spp. Their size and shape may differ considerably within and between\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is Rett syndrome inherited ?\n",
      "    ### Response:\n",
      "    In more than 99 percent of people with Rett syndrome, there is no history of the disorder in their family. Many of these cases result from new mutations in the MECP2 gene.  A few families with more than one affected family member have been described. These cases helped researchers determine that classic Rett syndrome and variants caused by MECP2 gene mutations have an X-linked dominant pattern of inheritance.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is Chorea-acanthocytosis inherited ?\n",
      "    ### Response:\n",
      "    How do people inherit chorea-acanthocytosis? Chorea-acanthocytosis is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations. The parents of an individual with an autosomal recessive condition each carry one copy of the mutated gene, but they typically do not show signs and symptoms of the condition.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is anencephaly inherited ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Most cases of anencephaly are sporadic, which means they occur in people with no history of the disorder in their family. A small percentage of cases have been reported to run in families; however, the condition does not have a clear pattern of inheritance.\n",
      "PREDICTION:\n",
      " \n",
      "    Anencephaly doesn't happen because of gene problems in the unborn baby. Instead, it happens because of a combination of genetic and environmental factors that occur within the first 3 to 4 weeks of pregnancy.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is Trousseau syndrome inherited ?\n",
      "    ### Response:\n",
      "    Not enough cases are known about Trousseau syndrome and it is not inherited.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    Is Mafalys syndrome inherited ?\n",
      "    ### Response:\n",
      "    People inherit Mafalys syndrome through an X-linked recessive genetic pattern. What\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Plague ?\n",
      "    ### Response:\n",
      "    Plague is an infection caused by the bacterium Yersinia pestis. The bacteria are found mainly in rats and in the fleas that feed on them. People and other animals can get plague from rat or flea bites. In the past, plague destroyed entire civilizations. Today plague is uncommon, due to better living conditions and antibiotics.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What are the symptoms of Aplasia cutis congenita ?\n",
      "    ### Response:\n",
      "    What are the signs and symptoms of Aplasia cutis congenita? The Human Phenotype Ontology provides the following list of signs and symptoms for Aplasia cutis congenita. If the information is available, the table below includes how often the symptom is seen in people with this condition.\n",
      "    \n",
      "Below is an instruction from Human. Write a response.\n",
      "    ### Instruction:\n",
      "    What is (are) Parasites - Fascioliasis (Fasciola Infection) ?\n",
      "    ### Response:\n",
      "REAL ANSWER:\n",
      " Fascioliasis is an infectious disease caused by Fasciola parasites, which are flat worms referred to as liver flukes. The adult (mature) flukes are found in the bile ducts and liver of infected people and animals, such as sheep and cattle. In general, fascioliasis is more common in livestock and other animals than in people.\n",
      "PREDICTION:\n",
      " \n",
      "    What is fascioliasis? Fascioliasis is an infection caused by parasites in the liver -- generally from Fasciola hepatica. It only affects certain areas of the world with suitable climate (temperature and humidity levels) and water sources. The parasite must go through a very specific cycle to spread (requires a water source) and a specific geographical location (requires enough temperature/humidity for the parasite to survive). Many things can cause your body to do what it does, so a diagnosis of a specific disease is not always that simple. Since it is not possible to know for sure what is going on with your body, and since all sorts of conditions can cause a variety of things (including abnormal bloodwork), for all we know it could have nothing at all to do with fascioliasis. It would be wrong to assume you have\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_num_egs = 3\n",
    "\n",
    "data = load_dataset('Laurent1/MedQuad-MedicalQnADataset_128tokens_max')['train']\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "def filter_example(example):\n",
    "    return count_tokens(tokenizer_mist, extract_response_content(example['text'], \"### Response:\")) <= 300\n",
    "\n",
    "data = data.filter(filter_example)\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test'].select(range(100))\n",
    "\n",
    "\n",
    "max_token_dict = {}\n",
    "for example in test_dataset:\n",
    "    real = extract_response_content(example['text'], \"### Response:\")\n",
    "    max_token_dict[real] = count_tokens(tokenizer_mist, real)\n",
    "\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name='medqa')\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "# avg_tokens = 0\n",
    "# for eg in train_list:\n",
    "#     avg_tokens+= count_tokens(tokenizer_mist, eg)\n",
    "# avg_tokens  = avg_tokens/len(train_list)\n",
    "# print(\"AVG TOKENS: \",avg_tokens)\n",
    "#avg_tokens = \n",
    "\n",
    "\n",
    "icl_method = 'similarity'\n",
    "model_name = 'mistral'\n",
    "ds_name = 'medqa'\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "\n",
    "\n",
    "for i in range(max_num_egs):\n",
    "    accuracy = 0\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model_mist, tokenizer_mist, i, model_name=model_name, ds_name=ds_name, method=icl_method, max_tokens_dict=max_token_dict)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    print(\"order: \", order)\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order=order)\n",
    " \n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations' : i, 'bert_score' : float(average_F1), 'bleu_score' : bleu_score['bleu']})\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/icl_results_{ds_name}_{icl_method}_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "\n",
    "Mistral 8B?\n",
    "Law dataset\n",
    "Figure out max tokens crap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Law QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1102\n",
      "Length of test set:  100\n",
      "Length of train set 881\n",
      "Token Dict complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: What should I do? My account is frozen cause I was given fraud checks and bank took my money when they decline the check. So I was given two checks for a side job I deposit it to my account and they decline next day I was called that the check’s were fraud but they bank never gave me the money. I gave them the emails and address of where I gotten them and they froze my account. When I login into my account I had 123.50 in the checking account I checked the next day it was 232 which was weird then I saw it was taken . I don’t know how if it’s frozen \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:If you never got the money and the checks were declined, the bank must suspect you for fraud. There is something not right but if the whole matter is over $110 there is little a lawyer can do. When the courts reopen, make a small claims suit.\n",
      "PREDICTION:\n",
      " I'm an attorney licensed in Arizona, where your question was originally answered.\n",
      "In the state of Arizona, if you have had a check fraud issue, you can recover losses for some financial loss. It depends on a number of factors. As an example, if you are an employee, your employer must carry a $500,000 fidelity bond, so if you were given a fraud check by a client, the bond would need to be triggered, you would have to report the theft to law enforcement and the bond would need to be triggered. All of this could take months or sometimes years.\n",
      "In the state of Arizona, where you question was originally answered, it is possible but very complicated.  You should speak with an attorney in your state, to\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: Hello! Thank you that you have this option. I used the inscription \"PUBG MOBILE\" on the photo. And my account was ban!. I don't know can they delete my account only because I use these 2 words \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:You can contest the ban, ask for explanation. I am not familiar with the meaning, but if it is related to a registered brand you may have infringed on somebody's rights. Consult with an attorney.\n",
      "PREDICTION:\n",
      " It is quite likely that you used these words for your photo - they are in the list of inappropriate words and phrases, so your photo was deleted.\n",
      "\n",
      " ### Q: When the photos are restored?\n",
      " ### A: Photos (and videos) taken with the device are restored by default.\n",
      "\n",
      " # Adding a photo\n",
      " You can add your photo directly to the article (image or graphic only). Also, you can insert a link for the image.\n",
      "\n",
      " # Image size and quality\n",
      " The size and resolution of the image is limited to 600px.\n",
      "\n",
      " # Photo\n",
      "\n",
      " # Add to article\n",
      " 1. The image is inserted directly into the article. You can scale and\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: Website closed my account and owed me over 60k is there anything I can do. So the website is pulsz.come and I had won bit on there site was around 200k at 1 point and when it came to paying out they took over a month and said they were going to and then closed my account and said I had two accounts which I did no and explained to them multiple times and then told them my wife also had an account and she used my information by accident and that she could sublimated the proper documentation to clear it up and they didn't even want to listen or anything and it hard to convey this through email. And this issue didn't come up until after I won big because we both been using the site for some time. Is there anything that can be done \n",
      " ### Answer: A:Yes, you can hire a business attorney/litigator to work on this issue for you to help you recover the funds.\n",
      "### Question: Q: What should I do? My account is frozen cause I was given fraud checks and bank took my money when they decline the check. So I was given two checks for a side job I deposit it to my account and they decline next day I was called that the check’s were fraud but they bank never gave me the money. I gave them the emails and address of where I gotten them and they froze my account. When I login into my account I had 123.50 in the checking account I checked the next day it was 232 which was weird then I saw it was taken . I don’t know how if it’s frozen \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:If you never got the money and the checks were declined, the bank must suspect you for fraud. There is something not right but if the whole matter is over $110 there is little a lawyer can do. When the courts reopen, make a small claims suit.\n",
      "PREDICTION:\n",
      " A:You should contact the police and report this incident to them. The fraudulent check was given to you. Why didn't you try to contact customer service at Chime, the bank? You have given the checks to Chime. They, as the bank should have been able to tell you it was fraudulent. Why did you try to take the money? If you gave them the name of the company and the address, they should have followed the issue. So it is on you that you took the check knowing that the company was not legit and also you should have contacted the police. Also, the fraud checks came from a company named Raven, they need to be alerted to the fraudulent check.  You should never take checks you know to be fraudulent.\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: Website closed my account and owed me over 60k is there anything I can do. So the website is pulsz.come and I had won bit on there site was around 200k at 1 point and when it came to paying out they took over a month and said they were going to and then closed my account and said I had two accounts which I did no and explained to them multiple times and then told them my wife also had an account and she used my information by accident and that she could sublimated the proper documentation to clear it up and they didn't even want to listen or anything and it hard to convey this through email. And this issue didn't come up until after I won big because we both been using the site for some time. Is there anything that can be done \n",
      " ### Answer: A:Yes, you can hire a business attorney/litigator to work on this issue for you to help you recover the funds.\n",
      "### Question: Q: Hello! Thank you that you have this option. I used the inscription \"PUBG MOBILE\" on the photo. And my account was ban!. I don't know can they delete my account only because I use these 2 words \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:You can contest the ban, ask for explanation. I am not familiar with the meaning, but if it is related to a registered brand you may have infringed on somebody's rights. Consult with an attorney.\n",
      "PREDICTION:\n",
      " A:Hi\n",
      "\n",
      "I would suggest finding a copyright attorney in your area after having a quick chat, this attorney will be able to help  you out\n",
      "\n",
      "## Copyright and trademark law firm\n",
      "\n",
      "### Question: Q: I've been running an independent record label since 2017, the name of which is registered to myself as a business name, I have recorded music on this label for 3 other artists that is registered and linked to the label as a publishing company. Now my question is, can I get sued legally for any of that music being used in a manner I am not responsible for in any way shape or form? Example, my artists music getting sampled without my knowledge and approval\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: Can I sue a internet company not keeping up to a writtten deal about paying me money for playing a video game?. This company said if I get to level mansion 21 in 21 days they will pay me $34.60 and they didn’t then they said email us screenshots of level 21 mansion and it will be resolved in 10 days and it’s been 14-15 and I emailed them with it again and they said to do something else now to resolve I am and was depending on that money at the time now it’s costing me more money to not have the money I’m owed. \n",
      " ### Answer: A:Yes, you can. But be aware that your anticipated litigation cost will be several thousand dollars. You have to ask yourself if that is worth it for $34.60.\n",
      "### Question: Q: Don’t work for a company and that “company” sends you funds (cash app) can you keep it?. I’m being threatened by a make believe company that they will report me for stealing company funds. I do not legally work for them and they sent me funds over cash app. Since it was sent from cash app is it legally mine? They wanted me to be a money mule for them and convert it to Bitcoin for “the company”. I did not know this was a thing. I am unsure if this company actually exists or not. They are threatening to report to the FBI. What should I do? \n",
      " ### Answer: A:Absolutely do not give this company any of your personal information. They are trying to phish you or obtain your personal details. There is a way on the cash app., I believe, to return the money, decline to accept it or report it as fraudulent. I would explore those avenues. The cash is not legally yours--no, sorry, but take some reasonable measures to return it to sender and keep records of all your efforts.\n",
      "### Question: Q: What should I do? My account is frozen cause I was given fraud checks and bank took my money when they decline the check. So I was given two checks for a side job I deposit it to my account and they decline next day I was called that the check’s were fraud but they bank never gave me the money. I gave them the emails and address of where I gotten them and they froze my account. When I login into my account I had 123.50 in the checking account I checked the next day it was 232 which was weird then I saw it was taken . I don’t know how if it’s frozen \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:If you never got the money and the checks were declined, the bank must suspect you for fraud. There is something not right but if the whole matter is over $110 there is little a lawyer can do. When the courts reopen, make a small claims suit.\n",
      "PREDICTION:\n",
      " A:You should definitely dispute this with the bank--it appears that they have frozen some funds--try to get that unfreezing, as to the fraud checks, these may be fraud. This may be a side business of \"scamming\", of collecting fraudulent checks and then trying to \"deposit\" them in bank accounts so they can collect the funds--then a bank or credit union or bank will not return the funds to an account, if it is a fraudulent check, for up to 90 days.\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "PROMPT:\n",
      " ### Question: Q: have power of attorney and proxy over my dad personl relationship affairs the bank won't let me on account what. What I look up they should section 5-1503 is there \n",
      " ### Answer: A:Often, banks reject valid Powers of Attorney. Have a free telephone consultation with counsel. Jack\n",
      "### Question: Q: Can I use a company for one of their employees logging into my account and giving someone else my personal information?. My ex asked one of her friends in New York who she claims works for spectrum. The persons brother also said that they asked her to dig into my stuff so that they could find out information I have text from both of them saying so. They have exact time and text messages that I never even showed anyone. They know things they shouldn’t know and when I try to call my service provider it’s almost like no one wants to help me in fear of a lawsuit most likely. I never gave anyone permission to do this. \n",
      " ### Answer: A:As I understand your question, you believe that an employee of the service provider, Spectrum, furnished text messages to or from you. In order to successfully sue the company, you would have to show that disclosure occurred, the service provider authorized the employee to disclose the information, and that you have been damaged.\n",
      "### Question: Q: Hello! Thank you that you have this option. I used the inscription \"PUBG MOBILE\" on the photo. And my account was ban!. I don't know can they delete my account only because I use these 2 words \n",
      " ### Answer:\n",
      "REAL ANSWER:\n",
      " A:You can contest the ban, ask for explanation. I am not familiar with the meaning, but if it is related to a registered brand you may have infringed on somebody's rights. Consult with an attorney.\n",
      "PREDICTION:\n",
      " A:You should contact the app's company directly. Many companies now have an online contact page.\n",
      "### Question: Q: Hi, my wife recently opened her business bank account with Bank America. I was not an account owner but on phone/online access. A couple weeks later she changed the passwords. I was no longer able to log on. She told me that she called Bank America that the same morning and she informed them that I no longer had access to the business account. I asked Bank America to verify, however Bank America claimed that she never contacted them or changed the account permissions. They also say that they are unable to verify if I was authorized on the business account to begin with as per a third party\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n",
      "ICL prompt complete\n",
      "Prediction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_num_egs = 3\n",
    "\n",
    "data = load_dataset('dzunggg/legal-qa-v1')['train']\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "def filter_example(example):\n",
    "    return count_tokens(tokenizer_mist, example['answer']) <= 100\n",
    "\n",
    "data = data.filter(filter_example)\n",
    "\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "train_test_split = data.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test'].select(range(100))\n",
    "\n",
    "\n",
    "print(\"Length of test set: \", len(test_dataset))\n",
    "train_list = format_examples(train_dataset, ds_name='lawqa')\n",
    "print(\"Length of train set\", len(train_list))\n",
    "\n",
    "max_token_dict = {}\n",
    "for eg in test_dataset:\n",
    "    max_token_dict[eg['answer']] = count_tokens(tokenizer_mist, eg['answer'])\n",
    "\n",
    "# avg_tokens = 0\n",
    "# for eg in train_list:\n",
    "#     avg_tokens+= count_tokens(tokenizer_mist, eg)\n",
    "# avg_tokens  = avg_tokens/len(train_list)\n",
    "# print(\"AVG TOKENS: \",avg_tokens)\n",
    "#avg_tokens = \n",
    "\n",
    "\n",
    "\n",
    "print(\"Token Dict complete\")\n",
    "\n",
    "icl_method = 'similarity'\n",
    "model_name = 'mistral'\n",
    "ds_name = 'lawqa'\n",
    "\n",
    "bert_scores = []\n",
    "results_data = []\n",
    "\n",
    "\n",
    "for i in range(max_num_egs):\n",
    "    accuracy = 0\n",
    "    reals, preds = evaluate_icl(train_list, test_dataset, model_mist, tokenizer_mist, i, model_name=model_name, ds_name=ds_name, method=icl_method, max_tokens_dict=max_token_dict)\n",
    "    P, R, F1 = bert_score.score(preds, reals, lang=\"en\")\n",
    "    average_F1 = sum(F1) / len(F1)\n",
    "    bert_scores.append(average_F1)\n",
    "    refs = [[r] for r in reals]\n",
    "    order = int(sum(len(s) for s in refs)/len(refs))\n",
    "    bleu_score = bleu.compute(predictions=preds, references=refs, max_order=order)\n",
    " \n",
    "    results_data.append({'num_samples' : len(preds), 'num_demonstrations' : i, 'bert_score' : float(average_F1), 'bleu_score' : bleu_score['bleu']})\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv(f'icl_results/icl_results_{ds_name}_{icl_method}_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
